{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## NLP Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(based on [YSDA](https://github.com/yandexdataschool/nlp_course) materials )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12612628</td>\n",
       "      <td>Engineering Systems Analyst</td>\n",
       "      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>\n",
       "      <td>Dorking, Surrey, Surrey</td>\n",
       "      <td>Dorking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>20000 - 30000/annum 20-30K</td>\n",
       "      <td>25000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12612830</td>\n",
       "      <td>Stress Engineer Glasgow</td>\n",
       "      <td>Stress Engineer Glasgow Salary **** to **** We...</td>\n",
       "      <td>Glasgow, Scotland, Scotland</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Gregory Martin International</td>\n",
       "      <td>Engineering Jobs</td>\n",
       "      <td>25000 - 35000/annum 25-35K</td>\n",
       "      <td>30000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                        Title  \\\n",
       "0  12612628  Engineering Systems Analyst   \n",
       "1  12612830      Stress Engineer Glasgow   \n",
       "\n",
       "                                     FullDescription  \\\n",
       "0  Engineering Systems Analyst Dorking Surrey Sal...   \n",
       "1  Stress Engineer Glasgow Salary **** to **** We...   \n",
       "\n",
       "                   LocationRaw LocationNormalized ContractType ContractTime  \\\n",
       "0      Dorking, Surrey, Surrey            Dorking          NaN    permanent   \n",
       "1  Glasgow, Scotland, Scotland            Glasgow          NaN    permanent   \n",
       "\n",
       "                        Company          Category                   SalaryRaw  \\\n",
       "0  Gregory Martin International  Engineering Jobs  20000 - 30000/annum 20-30K   \n",
       "1  Gregory Martin International  Engineering Jobs  25000 - 35000/annum 25-35K   \n",
       "\n",
       "   SalaryNormalized        SourceName  \n",
       "0             25000  cv-library.co.uk  \n",
       "1             30000  cv-library.co.uk  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
    "\n",
    "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# box-cox transforms the data to make it more normal\n",
    "\n",
    "def box_cox(x, lmbda):\n",
    "    if lmbda == 0:\n",
    "        return np.log(x + 1) # == np.log1p(x)\n",
    "    else:\n",
    "        return (x**lmbda - 1) / lmbda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99864</th>\n",
       "      <td>69538130</td>\n",
       "      <td>Oracle Consultant (ERP)</td>\n",
       "      <td>MCS Group are currently working with one of Ir...</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>Belfast</td>\n",
       "      <td>full_time</td>\n",
       "      <td>permanent</td>\n",
       "      <td>MCS Group</td>\n",
       "      <td>IT Jobs</td>\n",
       "      <td>40,000 - 50,000</td>\n",
       "      <td>45000</td>\n",
       "      <td>nijobfinder.co.uk</td>\n",
       "      <td>10.714440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170048</th>\n",
       "      <td>71352930</td>\n",
       "      <td>Pensions Administration Manager</td>\n",
       "      <td>Are you looking for a change and a move to Sun...</td>\n",
       "      <td>Malta Island</td>\n",
       "      <td>UK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Sammons Pensions</td>\n",
       "      <td>Accounting &amp; Finance Jobs</td>\n",
       "      <td>GBP35000 - 48000 per annum</td>\n",
       "      <td>41500</td>\n",
       "      <td>professionalpensionsjobs.com</td>\n",
       "      <td>10.633472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146878</th>\n",
       "      <td>70754568</td>\n",
       "      <td>Business Intelligence  Operational Analyst</td>\n",
       "      <td>Business Intelligence  Operational Analyst  Te...</td>\n",
       "      <td>Haywards Heath</td>\n",
       "      <td>Haywards Heath</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Centrepoint Recruitment Consultants</td>\n",
       "      <td>Admin Jobs</td>\n",
       "      <td>40000 - 48000 per annum</td>\n",
       "      <td>44000</td>\n",
       "      <td>MyUkJobs</td>\n",
       "      <td>10.691968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                       Title  \\\n",
       "99864   69538130                     Oracle Consultant (ERP)   \n",
       "170048  71352930             Pensions Administration Manager   \n",
       "146878  70754568  Business Intelligence  Operational Analyst   \n",
       "\n",
       "                                          FullDescription     LocationRaw  \\\n",
       "99864   MCS Group are currently working with one of Ir...         Belfast   \n",
       "170048  Are you looking for a change and a move to Sun...    Malta Island   \n",
       "146878  Business Intelligence  Operational Analyst  Te...  Haywards Heath   \n",
       "\n",
       "       LocationNormalized ContractType ContractTime  \\\n",
       "99864             Belfast    full_time    permanent   \n",
       "170048                 UK          NaN    permanent   \n",
       "146878     Haywards Heath          NaN          NaN   \n",
       "\n",
       "                                    Company                   Category  \\\n",
       "99864                             MCS Group                    IT Jobs   \n",
       "170048                     Sammons Pensions  Accounting & Finance Jobs   \n",
       "146878  Centrepoint Recruitment Consultants                 Admin Jobs   \n",
       "\n",
       "                         SalaryRaw  SalaryNormalized  \\\n",
       "99864              40,000 - 50,000             45000   \n",
       "170048  GBP35000 - 48000 per annum             41500   \n",
       "146878     40000 - 48000 per annum             44000   \n",
       "\n",
       "                          SourceName  Log1pSalary  \n",
       "99864              nijobfinder.co.uk    10.714440  \n",
       "170048  professionalpensionsjobs.com    10.633472  \n",
       "146878                      MyUkJobs    10.691968  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "TARGET_COLUMN = \"Log1pSalary\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "We have to lowercase and tokenize all texts under `Title` and `FullDescription` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mathematical',\n",
       " 'Modeller',\n",
       " '/',\n",
       " 'Simulation',\n",
       " 'Analyst',\n",
       " '/',\n",
       " 'Operational',\n",
       " 'Analyst',\n",
       " 'Basingstoke',\n",
       " ',',\n",
       " 'Hampshire',\n",
       " 'Up',\n",
       " 'to',\n",
       " '****',\n",
       " 'K',\n",
       " 'AAE',\n",
       " 'pension',\n",
       " 'contribution',\n",
       " ',',\n",
       " 'private',\n",
       " 'medical',\n",
       " 'and',\n",
       " 'dental',\n",
       " 'The',\n",
       " 'opportunity',\n",
       " 'Our',\n",
       " 'client',\n",
       " 'is',\n",
       " 'an',\n",
       " 'independent',\n",
       " 'consultancy',\n",
       " 'firm',\n",
       " 'which',\n",
       " 'has',\n",
       " 'an',\n",
       " 'opportunity',\n",
       " 'for',\n",
       " 'a',\n",
       " 'Data',\n",
       " 'Analyst',\n",
       " 'with',\n",
       " '35',\n",
       " 'years',\n",
       " 'experience',\n",
       " '.',\n",
       " 'The',\n",
       " 'role',\n",
       " 'will',\n",
       " 'require',\n",
       " 'the',\n",
       " 'successful',\n",
       " 'candidate',\n",
       " 'to',\n",
       " 'demonstrate',\n",
       " 'their',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'analyse',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'and',\n",
       " 'arrive',\n",
       " 'at',\n",
       " 'a',\n",
       " 'solution',\n",
       " ',',\n",
       " 'with',\n",
       " 'varying',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'data',\n",
       " 'being',\n",
       " 'available',\n",
       " '.',\n",
       " 'Essential',\n",
       " 'skills',\n",
       " 'Thorough',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'Excel',\n",
       " 'and',\n",
       " 'proven',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'utilise',\n",
       " 'this',\n",
       " 'to',\n",
       " 'create',\n",
       " 'powerful',\n",
       " 'decision',\n",
       " 'support',\n",
       " 'models',\n",
       " 'Experience',\n",
       " 'in',\n",
       " 'Modelling',\n",
       " 'and',\n",
       " 'Simulation',\n",
       " 'Techniques',\n",
       " ',',\n",
       " 'Experience',\n",
       " 'of',\n",
       " 'techniques',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Discrete',\n",
       " 'Event',\n",
       " 'Simulation',\n",
       " 'and',\n",
       " '/',\n",
       " 'or',\n",
       " 'SD',\n",
       " 'modelling',\n",
       " 'Mathematical',\n",
       " '/',\n",
       " 'scientific',\n",
       " 'background',\n",
       " 'minimum',\n",
       " 'degree',\n",
       " 'qualified',\n",
       " 'Proven',\n",
       " 'analytical',\n",
       " 'and',\n",
       " 'problem',\n",
       " 'solving',\n",
       " 'skills',\n",
       " 'Self',\n",
       " 'Starter',\n",
       " 'Ability',\n",
       " 'to',\n",
       " 'develop',\n",
       " 'solid',\n",
       " 'working',\n",
       " 'relationships',\n",
       " 'In',\n",
       " 'addition',\n",
       " 'to',\n",
       " 'formal',\n",
       " 'qualifications',\n",
       " 'and',\n",
       " 'experience',\n",
       " ',',\n",
       " 'the',\n",
       " 'successful',\n",
       " 'candidate',\n",
       " 'will',\n",
       " 'require',\n",
       " 'excellent',\n",
       " 'written',\n",
       " 'and',\n",
       " 'verbal',\n",
       " 'communication',\n",
       " 'skills',\n",
       " ',',\n",
       " 'be',\n",
       " 'energetic',\n",
       " ',',\n",
       " 'enterprising',\n",
       " 'and',\n",
       " 'have',\n",
       " 'a',\n",
       " 'determination',\n",
       " 'to',\n",
       " 'succeed',\n",
       " '.',\n",
       " 'They',\n",
       " 'will',\n",
       " 'be',\n",
       " 'required',\n",
       " 'to',\n",
       " 'build',\n",
       " 'solid',\n",
       " 'working',\n",
       " 'relationships',\n",
       " ',',\n",
       " 'both',\n",
       " 'internally',\n",
       " 'with',\n",
       " 'colleagues',\n",
       " 'and',\n",
       " ',',\n",
       " 'most',\n",
       " 'importantly',\n",
       " ',',\n",
       " 'externally',\n",
       " 'with',\n",
       " 'our',\n",
       " 'clients',\n",
       " '.',\n",
       " 'They',\n",
       " 'must',\n",
       " 'be',\n",
       " 'comfortable',\n",
       " 'working',\n",
       " 'independently',\n",
       " 'to',\n",
       " 'deliver',\n",
       " 'against',\n",
       " 'challenging',\n",
       " 'client',\n",
       " 'demands',\n",
       " '.',\n",
       " 'The',\n",
       " 'offices',\n",
       " 'are',\n",
       " 'located',\n",
       " 'in',\n",
       " 'Basingstoke',\n",
       " ',',\n",
       " 'Hampshire',\n",
       " ',',\n",
       " 'but',\n",
       " 'our',\n",
       " 'client',\n",
       " 'work',\n",
       " 'for',\n",
       " 'clients',\n",
       " 'worldwide',\n",
       " '.',\n",
       " 'The',\n",
       " 'successful',\n",
       " 'candidate',\n",
       " 'must',\n",
       " 'therefore',\n",
       " 'be',\n",
       " 'prepared',\n",
       " 'to',\n",
       " 'undertake',\n",
       " 'work',\n",
       " 'at',\n",
       " 'client',\n",
       " 'sites',\n",
       " 'for',\n",
       " 'short',\n",
       " 'periods',\n",
       " 'of',\n",
       " 'time',\n",
       " '.',\n",
       " 'Physics',\n",
       " ',',\n",
       " 'Mathematics',\n",
       " ',',\n",
       " 'Modelling',\n",
       " ',',\n",
       " 'Simulation',\n",
       " ',',\n",
       " 'Analytical',\n",
       " ',',\n",
       " 'Operational',\n",
       " 'Research',\n",
       " ',',\n",
       " 'Mathematical',\n",
       " 'Modelling',\n",
       " 'Mathematical',\n",
       " 'Modeller',\n",
       " '/',\n",
       " 'Simulation',\n",
       " 'Analyst',\n",
       " '/',\n",
       " 'Operational',\n",
       " 'Analyst',\n",
       " 'Basingstoke',\n",
       " ',',\n",
       " 'Hampshire',\n",
       " '****',\n",
       " 'K',\n",
       " 'AAE',\n",
       " 'pension',\n",
       " 'contribution',\n",
       " ',',\n",
       " 'private',\n",
       " 'medical',\n",
       " 'and',\n",
       " 'dental']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(data[\"FullDescription\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "data[\"Title\"] = [\n",
    "    ' '.join(tokenizer.tokenize(str(text).lower())) for text in data[\"Title\"]\n",
    "]\n",
    "data[\"FullDescription\"] = [\n",
    "    ' '.join(tokenizer.tokenize(str(text).lower())) for text in data[\"FullDescription\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next step is to build __Vocabulary__ : a set of all unique tokens with token to index and index to token mappings.\n",
    "\n",
    "Note that not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "\n",
    "for column in text_columns:\n",
    "    texts = data[column].values\n",
    "    \n",
    "    for text in texts:\n",
    "        token_counts.update(text.split())\n",
    "\n",
    "# for column in text_columns:\n",
    "#     texts = data[column].values\n",
    "    \n",
    "#     for t in texts:\n",
    "#         words = t.split()\n",
    "#         for word in words:\n",
    "#             token_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get a list of tokens that occur at least 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# YOUR CODE HERE\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size:\", len(tokens))\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNK',\n",
       " 'PAD',\n",
       " 'engineering',\n",
       " 'systems',\n",
       " 'analyst',\n",
       " 'stress',\n",
       " 'engineer',\n",
       " 'glasgow',\n",
       " 'modelling',\n",
       " 'and']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Build an inverse vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "token_to_id = {token: indx for indx, token in enumerate(tokens)}# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we will use vocabulary to convert text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAD'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(5)\n",
    "b = torch.randn(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a, b], dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[   2    3    4    1    1]\n",
      " [ 998  176    1    1    1]\n",
      " [  18 3472  242   59    6]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deep learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Log1pSalary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.2, inplace=False)\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear(128, 4096) # train: ~[bs, 4096 * (1 - 0.2)] || test: [bs, 4096]\n",
    "# nn.Dropout(0.2)      # train: [bs, 4096]  || test: * (1 - 0.2)\n",
    "# nn.Linear(4096, 1)   # [bs, 4096] -> [bs, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def to_tensors(batch, device):\n",
    "    batch_tensors = dict()\n",
    "    for key, arr in batch.items():\n",
    "        if key in [\"FullDescription\", \"Title\"]:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device, dtype=torch.int64)\n",
    "        else:\n",
    "            batch_tensors[key] = torch.tensor(arr, device=device)\n",
    "    return batch_tensors\n",
    "\n",
    "def make_batch(data, max_len=None, word_dropout=0, device=torch.device('cpu')):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len], 'FullDescription': int64[batch, max_len]}\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if TARGET_COLUMN in data.columns:\n",
    "        batch[TARGET_COLUMN] = data[TARGET_COLUMN].values\n",
    "    \n",
    "    return to_tensors(batch, device)\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': tensor([[   18,   287,   359,     1,     1,     1,     1],\n",
       "         [ 2863,    11,    12,    13,    55,    37, 12109],\n",
       "         [ 2833,   618,   858,    63,  7104,  7105,    64]]),\n",
       " 'FullDescription': tensor([[   18,   287,   359,  1408,   561,    18,   287,   359,  1464,  1408],\n",
       "         [ 2863,    11,    12,    13,    55,    37, 12109,  1767,  1166,    74],\n",
       "         [  142,  1617,  8830,  1314,  1464,   559,   560,   561,   618,   858]]),\n",
       " 'Log1pSalary': tensor([ 9.7115, 10.4631, 10.7144])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# [bs, seq_len, emb_dim]\n",
    "a = torch.randn(3, 10, 16)\n",
    "\n",
    "# [seq_len, bs, emb_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=16, hidden_size=64, bidirectional=True, batch_first=True)\n",
    "lstm = nn.LSTM(input_size=16, hidden_size=64, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gru_out, gru_hidden = gru(a)\n",
    "lstm_out, (lstm_hidden, _) = lstm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gru_out.shape # [3, 10, 128]\n",
    "gru_hidden.shape # [1 + bidirectional, 3, 64] \n",
    "\n",
    "gru_hidden = gru_hidden.view(gru_hidden.size(1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNNRegressor(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int = 64, hid_size: int = 64, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.title_emb = nn.Embedding(vocab_size, emb_size)\n",
    "        self.descr_emb = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "        self.title_gru = nn.GRU(input_size=emb_size, hidden_size=hid_size, batch_first=True, dropout=dropout)\n",
    "        self.descr_gru = nn.GRU(input_size=emb_size, hidden_size=hid_size, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # self.cat_encoder = nn.Linear(num_cat_features, hid_size)\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(2 * hid_size, hid_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_size, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        title = batch['Title'] # [bs, seq_len]\n",
    "        descr = batch['FullDescription']\n",
    "        \n",
    "        # squeeze: [1, a, b, 1, c, 1, 1, d] -> [a, b, c, d]\n",
    "        embed_title = self.title_emb(title) # [bs, seq_len, emb_dim]\n",
    "        _, title_hidden = self.title_gru(embed_title) # [1, bs(?=1), hid_size]\n",
    "        title_hidden = title_hidden.squeeze(0) # [bs, hid_size]\n",
    "        \n",
    "        embed_descr = self.descr_emb(descr) # [bs, seq_len, emb_dim]\n",
    "        _, descr_hidden = self.descr_gru(embed_descr) # [1, bs, hid_size]\n",
    "        descr_hidden = descr_hidden.squeeze(0) # [bs, hid_size]\n",
    "\n",
    "        # cat_features = self.cat_encoder(batch['Categorical']) # [bs, hid_size]\n",
    "        # concated = torch.cat([title_hidden, descr_hidden, cat_features], dim=1) # [bs, 3 * hid_size]\n",
    "\n",
    "        concated = torch.cat([title_hidden, descr_hidden], dim=1) # [bs, 2 * hid_size]\n",
    "        output = self.fully_connected(concated) # [bs, 1]\n",
    "        return output.squeeze(1) # [bs]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amarkov/.miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = RNNRegressor(len(tokens), emb_size=64, hid_size=64, dropout=0.2)\n",
    "batch = make_batch(data_train[:100])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "dummy_pred = model(batch)\n",
    "dummy_loss = criterion(dummy_pred, batch[TARGET_COLUMN])\n",
    "assert dummy_pred.shape == torch.Size([100])\n",
    "assert len(torch.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert dummy_loss.ndim == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, device=torch.device('cpu'), **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            yield batch\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(model, data, batch_size=BATCH_SIZE, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "            batch_pred = model(batch)\n",
    "            squared_error += torch.sum(torch.square(batch_pred - batch[TARGET_COLUMN]))\n",
    "            abs_error += torch.sum(torch.abs(batch_pred - batch[TARGET_COLUMN]))\n",
    "            num_samples += len(batch_pred)\n",
    "    mse = squared_error.detach().cpu().numpy() / num_samples\n",
    "    mae = abs_error.detach().cpu().numpy() / num_samples\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % mse)\n",
    "    print(\"Mean absolute error: %.5f\" % mae)\n",
    "    return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amarkov/.miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/var/folders/8z/rdxqfjbs0xx8flpxsgkvkxgw0000gn/T/ipykernel_1735/3993476165.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, batch in tqdm.tqdm_notebook(enumerate(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b55373a29b4e54a4687086ca49bc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1529 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb Cell 51\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001B[0m \u001B[39mfor\u001B[39;00m i, batch \u001B[39min\u001B[39;00m tqdm\u001B[39m.\u001B[39mtqdm_notebook(\u001B[39menumerate\u001B[39m(\n\u001B[1;32m      <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001B[0m         iterate_minibatches(data_train, batch_size\u001B[39m=\u001B[39mBATCH_SIZE, device\u001B[39m=\u001B[39mDEVICE)),\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001B[0m         total\u001B[39m=\u001B[39m\u001B[39mlen\u001B[39m(data_train) \u001B[39m/\u001B[39m\u001B[39m/\u001B[39m BATCH_SIZE\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001B[0m     ):\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001B[0m     y_true \u001B[39m=\u001B[39m batch\u001B[39m.\u001B[39mpop(TARGET_COLUMN)\n\u001B[0;32m---> <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001B[0m     y_pred \u001B[39m=\u001B[39m model(batch)\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001B[0m     loss \u001B[39m=\u001B[39m criterion(y_pred, y_true)\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=16'>17</a>\u001B[0m     optimizer\u001B[39m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/.miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1103\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "\u001B[1;32m/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb Cell 51\u001B[0m in \u001B[0;36mRNNRegressor.forward\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=25'>26</a>\u001B[0m title_hidden \u001B[39m=\u001B[39m title_hidden\u001B[39m.\u001B[39msqueeze(\u001B[39m0\u001B[39m) \u001B[39m# [bs, hid_size]\u001B[39;00m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=27'>28</a>\u001B[0m embed_descr \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mdescr_emb(descr) \u001B[39m# [bs, seq_len, emb_dim]\u001B[39;00m\n\u001B[0;32m---> <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=28'>29</a>\u001B[0m _, descr_hidden \u001B[39m=\u001B[39m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdescr_gru(embed_descr) \u001B[39m# [1, bs, hid_size]\u001B[39;00m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=29'>30</a>\u001B[0m descr_hidden \u001B[39m=\u001B[39m descr_hidden\u001B[39m.\u001B[39msqueeze(\u001B[39m0\u001B[39m) \u001B[39m# [bs, hid_size]\u001B[39;00m\n\u001B[1;32m     <a href='vscode-notebook-cell:/Users/amarkov/Documents/Work/ML_in_SWE/lectures/sem5/neural_nets_for_text.ipynb#X50sZmlsZQ%3D%3D?line=32'>33</a>\u001B[0m concated \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mcat([title_hidden, descr_hidden], dim\u001B[39m=\u001B[39m\u001B[39m1\u001B[39m) \u001B[39m# [bs, 2 * hid_size]\u001B[39;00m\n",
      "File \u001B[0;32m~/.miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1098\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1099\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1103\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:849\u001B[0m, in \u001B[0;36mGRU.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    847\u001B[0m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcheck_forward_args(\u001B[39minput\u001B[39m, hx, batch_sizes)\n\u001B[1;32m    848\u001B[0m \u001B[39mif\u001B[39;00m batch_sizes \u001B[39mis\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m--> 849\u001B[0m     result \u001B[39m=\u001B[39m _VF\u001B[39m.\u001B[39;49mgru(\u001B[39minput\u001B[39;49m, hx, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49m_flat_weights, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbias, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mnum_layers,\n\u001B[1;32m    850\u001B[0m                      \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdropout, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtraining, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbidirectional, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mbatch_first)\n\u001B[1;32m    851\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    852\u001B[0m     result \u001B[39m=\u001B[39m _VF\u001B[39m.\u001B[39mgru(\u001B[39minput\u001B[39m, batch_sizes, hx, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_flat_weights, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbias,\n\u001B[1;32m    853\u001B[0m                      \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mnum_layers, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mdropout, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtraining, \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mbidirectional)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = RNNRegressor(len(tokens), emb_size=64, hid_size=64, dropout=0.2).to(DEVICE)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    model.train()\n",
    "    for i, batch in tqdm.tqdm_notebook(enumerate(\n",
    "            iterate_minibatches(data_train, batch_size=BATCH_SIZE, device=DEVICE)),\n",
    "            total=len(data_train) // BATCH_SIZE\n",
    "        ):\n",
    "        y_true = batch.pop(TARGET_COLUMN)\n",
    "        y_pred = model(batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_true)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        \n",
    "    print_metrics(model, data_val)\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d189d21d977b81210d15f909fc18f2c540b65e67432daf72fa2f119ed5a0108c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}