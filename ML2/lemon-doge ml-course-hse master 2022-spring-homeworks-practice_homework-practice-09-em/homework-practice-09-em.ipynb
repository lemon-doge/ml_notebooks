{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "# Практическое задание 9. EM-алгоритм\n",
    "\n",
    "## Общая информация\n",
    "\n",
    "Дата выдачи: 27.02.2023\n",
    "\n",
    "Мягкий дедлайн: 18.03.2023 23:59 MSK\n",
    "\n",
    "Жёсткий дедлайн: 25.03.2023 23:59 MSK\n",
    "\n",
    "## Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 15 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "## Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-09-em-Username.ipynb\n",
    "* Модули preprocessing.py, metrics.py, models.py, содержащие написанный вами код\n",
    "* Ссылки на посылки в Яндекс.Контест для всех функций и классов, которые вы реализовали\n",
    "\n",
    "Ссылка на Яндекс.Контест: https://contest.yandex.ru/contest/46988\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generative model of Labels, Abilities, and Difficulties (GLAD)\n",
    "\n",
    "В [семинаре 16](https://github.com/esokolov/ml-course-hse/blob/master/2022-spring/seminars/sem16-em.pdf) мы рассмотрели задачу восстановления истинной разметки по меткам от экспертов (которым мы не можем доверять в полной мере, более того, их предсказания могут расходиться).\n",
    "\n",
    "Рассмотрим следующую вероятностную модель:\n",
    "\n",
    "$$ p(L, Z | \\alpha, \\beta) = \\prod_{i=1}^{n} \\prod_{j=1}^m \\sigma(\\alpha_j\\beta_i)^{[l_{ij}=z_i]}\\sigma(-\\alpha_j\\beta_i)^{1-[l_{ij}=z_i]} p(z_j)$$\n",
    "\n",
    "где $l_{ij} -$ ответ $j$-го эксперта на задачу $i$, $z_j -$ истинная разметка, $\\alpha_i, \\beta_j-$ уровень экспертизы и сложность задачи соответственно. Для более подробного описания модели можно прочитать материалы семинара, а также [оригинальную статью](http://papers.nips.cc/paper/3644-whose-vote-should-count-more-optimal-integration-of-labels-from-labelers-of-unknown-expertise.pdf). Априорное распределение положим равномерным: $p(z_i) = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 0xDEADF00D\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "L = np.load('L.npy')\n",
    "n, m = L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 20)"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 1. (2 балла)** Реализуйте EM-алгоритм для заданной выше модели. Вы можете воспользоваться предложенными шаблонами или написать свои. \n",
    "\n",
    "Обратите внимание, что правдоподобие моделирует не вероятность метки $l_{ij}$ принять значение 1 или 0, а вероятность того, что она равна скрытой переменной $z_i$, т.е. $p(l_{ij} = z_j|z_j, \\alpha_j, \\beta_i) \\neq p(l_{ij} = 1|\\alpha_j, \\beta_i) $. При этом заранее неизвестно, какая из скрытых переменных соответствует метке 1. Не забывайте, что параметры $\\beta_i$ должны быть неотрицательными; для этого оптимизируйте $\\log \\beta$. На M-шаге можете использовать как один шаг градиентного спуска, так и несколько: разумные результаты у вас должны получаться вне зависимости от числа итераций.\n",
    "\n",
    "Также при работе с вероятностями не забывайте о точности:\n",
    "1. Используйте логарифмы вероятностей.\n",
    "2. $\\log \\sigma(a)$ лучше преобразовать в $\\log \\sigma(a) = -\\log(1 + \\exp(-a)) = -\\mathrm{softplus}(-a) $\n",
    "3. Ещё полезные функции: `scipy.special.expit`, `scipy.special.logsumexp`, `np.log1p`\n",
    "\n",
    "Для отладки может быть полезно проверить градиент с помощью `scipy.optimize.check_grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    '''stable version of log(1 + exp(x))'''\n",
    "    c = (x > 20) * 1.\n",
    "    return np.log1p(np.exp(x * (1 - c)) * (1 - c)) + x * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def aprior(t):\n",
    "    return 0.5 * np.ones_like(t)\n",
    "\n",
    "\n",
    "# t: n x 1, {0,1}\n",
    "# L: n - tasks x m - experts\n",
    "# alpha: m x 1\n",
    "# beta: n x 1\n",
    "def gamma(alpha, beta, L, t):\n",
    "    beta_alpha = beta.dot(alpha.T)\n",
    "    return np.log(aprior(t)) + np.sum(((1 - np.abs(L - t)) * (-softplus(-beta_alpha)) +\n",
    "                                       np.abs(L - t) * (-softplus(beta_alpha))),axis=1).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def posterior(alpha, beta, L):\n",
    "    \"\"\" Posterior over true labels z p(z|l, \\alpha, \\beta)\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts, 1).\n",
    "        beta: ndarray of shape (n_problems, 1).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "    \"\"\"\n",
    "    gamma_exp_ones = np.exp(gamma(alpha,beta,L,np.ones_like(beta)))\n",
    "    gamma_exp_zeros = np.exp(gamma(alpha,beta,L,np.zeros_like(beta)))\n",
    "    return np.array([gamma_exp_zeros / (gamma_exp_zeros + gamma_exp_ones),\n",
    "                     gamma_exp_ones / (gamma_exp_zeros + gamma_exp_ones)]).squeeze(axis=2)\n",
    "\n",
    "\n",
    "def log_likelihood(alpha, beta, L, z):\n",
    "    \"\"\" log(p(l,z|alpha, beta))\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts,1).\n",
    "        beta: ndarray of shape (n_problems,1).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        z: ndarray of shape (n_problems,1).\n",
    "    \"\"\"\n",
    "    z = z.reshape(-1, 1)\n",
    "    beta_alpha = beta.dot(alpha.T)\n",
    "    return np.sum(np.log(aprior(z)) +\n",
    "                  np.sum(((1 - np.abs(L - z)) * (-softplus(-beta_alpha)) +\n",
    "                          np.abs(L - z) * (-softplus(beta_alpha))), axis=1).reshape(-1, 1), axis = 0)\n",
    "\n",
    "\n",
    "def alpha_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt alpha\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts,1).\n",
    "        beta: ndarray of shape (n_problems,1).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    beta_alpha = beta.dot(alpha.T)\n",
    "    return np.sum(q[0].reshape(-1, 1) * beta * ((1 - np.abs(L - 0)) * expit(-beta_alpha) - np.abs(L - 0) * expit(beta_alpha)),axis=0) +\\\n",
    "           np.sum(q[1].reshape(-1, 1) * beta * ((1 - np.abs(L - 1)) * expit(-beta_alpha) - np.abs(L - 1) * expit(beta_alpha)), axis=0)\n",
    "\n",
    "\n",
    "def logbeta_grad_lb(alpha, beta, L, q):\n",
    "    \"\"\" Gradient of lower bound wrt beta\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts,1).\n",
    "        beta: ndarray of shape (n_problems,1).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    beta_alpha = beta.dot(alpha.T)\n",
    "    return np.sum(q[0].reshape(-1, 1).dot(alpha.reshape(1, -1)) * ((1 - np.abs(L - 0)) * expit(-beta_alpha) - np.abs(L - 0) * expit(beta_alpha)),axis=1).reshape(-1,1) * beta + \\\n",
    "           np.sum(q[1].reshape(-1, 1).dot(alpha.reshape(1, -1)) * ((1 - np.abs(L - 1)) * expit(-beta_alpha) - np.abs(L - 1) * expit(beta_alpha)), axis=1).reshape(-1,1) * beta # dL/d(logb) = b * dL/db\n",
    "\n",
    "\n",
    "def lower_bound(alpha, beta, L, q):\n",
    "    \"\"\" Lower bound\n",
    "    Args:\n",
    "        alpha: ndarray of shape (n_experts,1).\n",
    "        beta: ndarray of shape (n_problems,1).\n",
    "        L: ndarray of shape (n_problems, n_experts).\n",
    "        q: ndarray of shape (2, n_problems).\n",
    "    \"\"\"\n",
    "    return np.sum(q[0] * (log_likelihood(alpha, beta, L, np.zeros_like(beta)) - np.log(q[0]))) +\\\n",
    "           np.sum(q[1] * (log_likelihood(alpha, beta, L, np.ones_like(beta)) - np.log(q[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "outputs": [],
   "source": [
    "alpha = 0.5 * np.ones(shape=L.shape[1]).reshape(-1,1)\n",
    "beta = 0.5 * np.ones(shape=L.shape[0]).reshape(-1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "outputs": [
    {
     "data": {
      "text/plain": "(2000, 1)"
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-15.21193558],\n       [-15.46193558],\n       [-15.71193558],\n       ...,\n       [-14.71193558],\n       [-14.21193558],\n       [-13.96193558]])"
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma(alpha, beta, L, np.zeros(shape=(n, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.26894142, 0.18242552, 0.11920292, ..., 0.5       , 0.73105858,\n        0.81757448],\n       [0.73105858, 0.81757448, 0.88079708, ..., 0.5       , 0.26894142,\n        0.18242552]])"
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior(alpha, beta, L)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-29467.87115627])"
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood(alpha,beta, L, np.zeros(shape=(n, 1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  90.98757   ,  102.38060166,  202.34218692,   74.77109954,\n         89.77971282,  194.56505413,   85.74859733,  198.22514823,\n       -300.00731975,   91.7681347 , -300.27382731, -302.93757496,\n        201.97076252,   82.72548346,   91.35649788,   77.13344148,\n         95.5553415 ,  201.28648552, -300.5302733 ,  196.32314174])"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_grad_lb(alpha,\n",
    "              beta,\n",
    "              L,\n",
    "              posterior(alpha, beta, L))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.37188327],\n       [-0.08168839],\n       [ 0.08878614],\n       ...,\n       [-0.11281765],\n       [-0.22940409],\n       [-0.05947981]])"
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logbeta_grad_lb(alpha,\n",
    "              beta,\n",
    "              L,\n",
    "              posterior(alpha, beta, L))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "outputs": [
    {
     "data": {
      "text/plain": "-58845374.34981295"
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_bound(alpha,\n",
    "              beta,\n",
    "              L,\n",
    "              posterior(alpha, beta, L))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "outputs": [],
   "source": [
    "def em(L, n_steps=1000, lr=1e-3):\n",
    "    # initialize parameters\n",
    "    alpha, logbeta = np.random.randn(m).reshape(-1,1), np.random.randn(n).reshape(-1,1)\n",
    "    q = np.ones((2, len(logbeta))) * 0.5\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        # E-step\n",
    "        q = posterior(alpha, np.exp(logbeta), L)\n",
    "        # M-step\n",
    "        alpha += lr * alpha_grad_lb(alpha, np.exp(logbeta), L, q).reshape(-1,1)\n",
    "        logbeta += lr * logbeta_grad_lb(alpha, np.exp(logbeta), L, q).reshape(-1,1)\n",
    "        print(lower_bound(alpha, np.exp(logbeta), L, q))\n",
    "\n",
    "    return alpha, np.exp(logbeta), q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-72978933.58116308\n",
      "-79092708.26780102\n",
      "-79069114.69149955\n",
      "-80249187.26072952\n",
      "-82084142.74699526\n",
      "-83098435.8074439\n",
      "-84164101.34805512\n",
      "-84894926.65515295\n",
      "-85616006.5915514\n",
      "-86185597.05893034\n",
      "-86732213.07247281\n",
      "-87203914.22299148\n",
      "-87653479.37354279\n",
      "-88062680.14836702\n",
      "-88453781.3911314\n",
      "-88821208.90380058\n",
      "-89174575.14215313\n",
      "-89512842.625215\n",
      "-89840319.06098184\n",
      "-90157382.30325657\n",
      "-90466104.66156843\n",
      "-90767150.38950327\n",
      "-91061628.46699232\n",
      "-91350140.76808053\n",
      "-91633354.49032202\n",
      "-91911740.05057865\n",
      "-92185739.8474465\n",
      "-92455707.02548252\n",
      "-92721955.33104333\n",
      "-92984749.78178692\n",
      "-93244322.99238205\n",
      "-93500876.90792203\n",
      "-93754589.50473788\n",
      "-94005617.7929211\n",
      "-94254101.3571553\n",
      "-94500164.7814368\n",
      "-94743919.85706295\n",
      "-94985467.32690948\n",
      "-95224898.37676695\n",
      "-95462295.87103373\n",
      "-95697735.40000506\n",
      "-95931286.16453743\n",
      "-96163011.72976395\n",
      "-96392970.66912998\n",
      "-96621217.11763039\n",
      "-96847801.24891666\n",
      "-97072769.68859561\n",
      "-97296165.87367871\n",
      "-97518030.36638775\n",
      "-97738401.12920387\n",
      "-97957313.76679823\n",
      "-98174801.73958132\n",
      "-98390896.55281839\n",
      "-98605627.9246752\n",
      "-98819023.93595558\n",
      "-99031111.16397384\n",
      "-99241914.80254564\n",
      "-99451458.76982862\n",
      "-99659765.80550721\n",
      "-99866857.55858216\n",
      "-100072754.6668604\n",
      "-100277476.82910158\n",
      "-100481042.87062448\n",
      "-100683470.80310035\n",
      "-100884777.87915084\n",
      "-101084980.64232364\n",
      "-101284094.97285025\n",
      "-101482136.12970652\n",
      "-101679118.78926174\n",
      "-101875057.08089942\n",
      "-102069964.61986917\n",
      "-102263854.53762549\n",
      "-102456739.50994563\n",
      "-102648631.78292169\n",
      "-102839543.19711328\n",
      "-103029485.2099703\n",
      "-103218468.91667579\n",
      "-103406505.06959277\n",
      "-103593604.09633195\n",
      "-103779776.1166578\n",
      "-103965030.9582917\n",
      "-104149378.1716265\n",
      "-104332827.04356956\n",
      "-104515386.61049457\n",
      "-104697065.67035355\n",
      "-104877872.79410228\n",
      "-105057816.33639443\n",
      "-105236904.44563964\n",
      "-105415145.07350107\n",
      "-105592545.9837922\n",
      "-105769114.76091662\n",
      "-105944858.81777403\n",
      "-106119785.40327325\n",
      "-106293901.60938619\n",
      "-106467214.3778343\n",
      "-106639730.5064216\n",
      "-106811456.65501095\n",
      "-106982399.35118507\n",
      "-107152564.99561808\n",
      "-107321959.86716756\n",
      "-107490590.12769353\n",
      "-107658461.82664022\n",
      "-107825580.90538508\n",
      "-107991953.20136237\n",
      "-108157584.45199135\n",
      "-108322480.29841277\n",
      "-108486646.28902254\n",
      "-108650087.88286425\n",
      "-108812810.45282747\n",
      "-108974819.28871599\n",
      "-109136119.60015792\n",
      "-109296716.51938877\n",
      "-109456615.10389388\n",
      "-109615820.3389242\n",
      "-109774337.13992605\n",
      "-109932170.35480808\n",
      "-110089324.7661579\n",
      "-110245805.09331748\n",
      "-110401615.99438679\n",
      "-110556762.06813568\n",
      "-110711247.85581794\n",
      "-110865077.84292503\n",
      "-111018256.46083218\n",
      "-111170788.08840224\n",
      "-111322677.05350918\n",
      "-111473927.634489\n",
      "-111624544.06152803\n",
      "-111774530.51799934\n",
      "-111923891.14173755\n",
      "-112072630.0262717\n",
      "-112220751.2219643\n",
      "-112368258.73715198\n",
      "-112515156.53921908\n",
      "-112661448.55561204\n",
      "-112807138.67483203\n",
      "-112952230.74737607\n",
      "-113096728.58664125\n",
      "-113240635.96979186\n",
      "-113383956.63858701\n",
      "-113526694.30019447\n",
      "-113668852.62793171\n",
      "-113810435.26201518\n",
      "-113951445.81026936\n",
      "-114091887.84879158\n",
      "-114231764.92261086\n",
      "-114371080.54631037\n",
      "-114509838.20462787\n",
      "-114648041.35303277\n",
      "-114785693.4182806\n",
      "-114922797.79894665\n",
      "-115059357.86593896\n",
      "-115195376.96299206\n",
      "-115330858.40714195\n",
      "-115465805.48918337\n",
      "-115600221.4741105\n",
      "-115734109.60154107\n",
      "-115867473.08612509\n",
      "-116000315.11793885\n",
      "-116132638.86286272\n",
      "-116264447.46295553\n",
      "-116395744.03679563\n",
      "-116526531.6798302\n",
      "-116656813.46470231\n",
      "-116786592.44156466\n",
      "-116915871.63840315\n",
      "-117044654.06130445\n",
      "-117172942.6947737\n",
      "-117300740.5019913\n",
      "-117428050.42508502\n",
      "-117554875.38539374\n",
      "-117681218.28371643\n",
      "-117807082.00055522\n",
      "-117932469.39635092\n",
      "-118057383.31171113\n",
      "-118181826.56763136\n",
      "-118305801.96570945\n",
      "-118429312.28835338\n",
      "-118552360.2989831\n",
      "-118674948.74222621\n",
      "-118797080.3441062\n",
      "-118918757.812235\n",
      "-119039983.83598004\n",
      "-119160761.08664513\n",
      "-119281092.21764548\n",
      "-119400979.8646608\n",
      "-119520426.6458036\n",
      "-119639435.16177335\n",
      "-119758007.99600855\n",
      "-119876147.71483251\n",
      "-119993856.86760624\n",
      "-120111137.98685609\n",
      "-120227993.58841966\n",
      "-120344426.17157727\n",
      "-120460438.21918258\n",
      "-120576032.19778988\n",
      "-120691210.55777869\n",
      "-120805975.73347516\n",
      "-120920330.14327113\n",
      "-121034276.18974006\n",
      "-121147816.25975089\n",
      "-121260952.72457916\n",
      "-121373687.94001597\n",
      "-121486024.24647667\n",
      "-121597963.96909699\n",
      "-121709509.41784611\n",
      "-121820662.88762666\n",
      "-121931426.65836336\n",
      "-122041802.99510795\n",
      "-122151794.14813213\n",
      "-122261402.35302092\n",
      "-122370629.83076248\n",
      "-122479478.78784664\n",
      "-122587951.41634114\n",
      "-122696049.89398767\n",
      "-122803776.38428576\n",
      "-122911133.03657775\n",
      "-123018121.9861285\n",
      "-123124745.35422438\n",
      "-123231005.2482278\n",
      "-123336903.76167879\n",
      "-123442442.97437397\n",
      "-123547624.95242926\n",
      "-123652451.7483719\n",
      "-123756925.40121335\n",
      "-123861047.93652555\n",
      "-123964821.36651649\n",
      "-124068247.69010508\n",
      "-124171328.89299536\n",
      "-124274066.94775045\n",
      "-124376463.81386544\n",
      "-124478521.43784022\n",
      "-124580241.75325185\n",
      "-124681626.68082616\n",
      "-124782678.12850946\n",
      "-124883397.99153948\n",
      "-124983788.1525164\n",
      "-125083850.48147133\n",
      "-125183586.83594477\n",
      "-125282999.06104444\n",
      "-125382088.98952565\n",
      "-125480858.44185063\n",
      "-125579309.22627088\n",
      "-125677443.13888836\n",
      "-125775261.9637273\n",
      "-125872767.47280353\n",
      "-125969961.4261963\n",
      "-126066845.57211143\n",
      "-126163421.64695504\n",
      "-126259691.37540735\n",
      "-126355656.47048627\n",
      "-126451318.63361704\n",
      "-126546679.55471046\n",
      "-126641740.91222051\n",
      "-126736504.37322277\n",
      "-126830971.59348272\n",
      "-126925144.21752623\n",
      "-127019023.87871024\n",
      "-127112612.19929357\n",
      "-127205910.79050815\n",
      "-127298921.25263011\n",
      "-127391645.17505154\n",
      "-127484084.13635409\n",
      "-127576239.70437294\n",
      "-127668113.43628328\n",
      "-127759706.87865648\n",
      "-127851021.56754926\n",
      "-127942059.02856016\n",
      "-128032820.7769155\n",
      "-128123308.31754257\n",
      "-128213523.14513543\n",
      "-128303466.74423127\n",
      "-128393140.58928846\n",
      "-128482546.14475952\n",
      "-128571684.8651618\n",
      "-128660558.1951694\n",
      "-128749167.5696614\n",
      "-128837514.41382065\n",
      "-128925600.1431995\n",
      "-129013426.16379805\n",
      "-129100993.87214059\n",
      "-129188304.65535244\n",
      "-129275359.89123912\n",
      "-129362160.94835335\n",
      "-129448709.18609306\n",
      "-129535005.9547545\n",
      "-129621052.59563687\n",
      "-129706850.4410938\n",
      "-129792400.81463031\n",
      "-129877705.03096882\n",
      "-129962764.39614049\n",
      "-130047580.20755577\n",
      "-130132153.75408575\n",
      "-130216486.31614122\n",
      "-130300579.16575217\n",
      "-130384433.5666473\n",
      "-130468050.77433372\n",
      "-130551432.03617868\n",
      "-130634578.59148145\n",
      "-130717491.6715653\n",
      "-130800172.49984953\n",
      "-130882622.29193163\n",
      "-130964842.25566733\n",
      "-131046833.59124887\n",
      "-131128597.49128917\n",
      "-131210135.1409064\n",
      "-131291447.71778728\n",
      "-131372536.39228219\n",
      "-131453402.32748097\n",
      "-131534046.67929116\n",
      "-131614470.59652609\n",
      "-131694675.22097264\n",
      "-131774661.68747935\n",
      "-131854431.12403223\n",
      "-131933984.65184015\n",
      "-132013323.38541096\n",
      "-132092448.4326261\n",
      "-132171360.89482658\n",
      "-132250061.86688745\n",
      "-132328552.4373053\n",
      "-132406833.68826419\n",
      "-132484906.69572051\n",
      "-132562772.52948716\n",
      "-132640432.25329927\n",
      "-132717886.92489797\n",
      "-132795137.59611401\n",
      "-132872185.31293213\n",
      "-132949031.11557658\n",
      "-133025676.03858508\n",
      "-133102121.11088513\n",
      "-133178367.35586752\n",
      "-133254415.79147011\n",
      "-133330267.43023999\n",
      "-133405923.27941671\n",
      "-133481384.34100412\n",
      "-133556651.61184403\n",
      "-133631726.08368954\n",
      "-133706608.7432757\n",
      "-133781300.57239996\n",
      "-133855802.54797956\n",
      "-133930115.64213943\n",
      "-134004240.82226625\n",
      "-134078179.0510913\n",
      "-134151931.28675973\n",
      "-134225498.48289168\n",
      "-134298881.58865085\n",
      "-134372081.54882276\n",
      "-134445099.30387565\n",
      "-134517935.7900233\n",
      "-134590591.93929315\n",
      "-134663068.67960626\n",
      "-134735366.93481496\n",
      "-134807487.62479216\n",
      "-134879431.6654759\n",
      "-134951199.9689469\n",
      "-135022793.44348413\n",
      "-135094212.99362206\n",
      "-135165459.52021778\n",
      "-135236533.92050648\n",
      "-135307437.08816907\n",
      "-135378169.91337794\n",
      "-135448733.28286326\n",
      "-135519128.07996538\n",
      "-135589355.18469954\n",
      "-135659415.47379827\n",
      "-135729309.82077274\n",
      "-135799039.09597212\n",
      "-135868604.16662252\n",
      "-135938005.89689505\n",
      "-136007245.147941\n",
      "-136076322.77795857\n",
      "-136145239.64222413\n",
      "-136213996.59316516\n",
      "-136282594.48037976\n",
      "-136351034.15070844\n",
      "-136419316.44826317\n",
      "-136487442.21447963\n",
      "-136555412.28816748\n",
      "-136623227.50554132\n",
      "-136690888.70027187\n",
      "-136758396.70352367\n",
      "-136825752.34400392\n",
      "-136892956.4479882\n",
      "-136960009.83937627\n",
      "-137026913.33971345\n",
      "-137093667.76824236\n",
      "-137160273.9419316\n",
      "-137226732.67551446\n",
      "-137293044.78151828\n",
      "-137359211.0703017\n",
      "-137425232.35009408\n",
      "-137491109.42701247\n",
      "-137556843.10510942\n",
      "-137622434.1863886\n",
      "-137687883.47084245\n",
      "-137753191.75647792\n",
      "-137818359.83934242\n",
      "-137883388.51355818\n",
      "-137948278.57133567\n",
      "-138013030.80300662\n",
      "-138077645.9970457\n",
      "-138142124.94009364\n",
      "-138206468.4169792\n",
      "-138270677.21074063\n",
      "-138334752.10264575\n",
      "-138398693.8722077\n",
      "-138462503.29721963\n",
      "-138526181.15374607\n",
      "-138589728.21616432\n",
      "-138653145.2571624\n",
      "-138716433.04776824\n",
      "-138779592.35735643\n",
      "-138842623.9536655\n",
      "-138905528.60280484\n",
      "-138968307.06927064\n",
      "-139030960.11595947\n",
      "-139093488.50418037\n",
      "-139155892.9936564\n",
      "-139218174.3425355\n",
      "-139280333.30739868\n",
      "-139342370.6432819\n",
      "-139404287.10365742\n",
      "-139466083.44045472\n",
      "-139527760.40406507\n",
      "-139589318.74335015\n",
      "-139650759.20562953\n",
      "-139712082.53669566\n",
      "-139773289.48081857\n",
      "-139834380.78074276\n",
      "-139895357.17768258\n",
      "-139956219.4113325\n",
      "-140016968.21986872\n",
      "-140077604.33992955\n",
      "-140138128.50663465\n",
      "-140198541.4535744\n",
      "-140258843.91280258\n",
      "-140319036.61483943\n",
      "-140379120.28866363\n",
      "-140439095.66171312\n",
      "-140498963.45987654\n",
      "-140558724.40748295\n",
      "-140618379.22730184\n",
      "-140677928.64053416\n",
      "-140737373.36680526\n",
      "-140796714.1241567\n",
      "-140855951.62903625\n",
      "-140915086.59629494\n",
      "-140974119.73917362\n",
      "-141033051.76928756\n",
      "-141091883.39663026\n",
      "-141150615.32954448\n",
      "-141209248.2747358\n",
      "-141267782.93723255\n",
      "-141326220.02039874\n",
      "-141384560.2258991\n",
      "-141442804.2537195\n",
      "-141500952.8021149\n",
      "-141559006.56761873\n",
      "-141616966.24502933\n",
      "-141674832.52738604\n",
      "-141732606.10597292\n",
      "-141790287.67028183\n",
      "-141847877.90800816\n",
      "-141905377.50503564\n",
      "-141962787.14542508\n",
      "-142020107.51139456\n",
      "-142077339.2832998\n",
      "-142134483.13962203\n",
      "-142191539.75695792\n",
      "-142248509.809991\n",
      "-142305393.9714828\n",
      "-142362192.91225475\n",
      "-142418907.30116823\n",
      "-142475537.80511642\n",
      "-142532085.08899415\n",
      "-142588549.8156892\n",
      "-142644932.6460602\n",
      "-142701234.23892766\n",
      "-142757455.25104144\n",
      "-142813596.3370756\n",
      "-142869658.1496122\n",
      "-142925641.33910716\n",
      "-142981546.55388254\n",
      "-143037374.44012052\n",
      "-143093125.64181876\n",
      "-143148800.80079708\n",
      "-143204400.5566625\n",
      "-143259925.5467975\n",
      "-143315376.40634805\n",
      "-143370753.76819295\n",
      "-143426058.26293194\n",
      "-143481290.5188719\n",
      "-143536451.1620043\n",
      "-143591540.81598336\n",
      "-143646560.10211027\n",
      "-143701509.63932723\n",
      "-143756390.04418343\n",
      "-143811201.93082148\n",
      "-143865945.91096163\n",
      "-143920622.5938906\n",
      "-143975232.58642966\n",
      "-144029776.49293157\n",
      "-144084254.91525733\n",
      "-144138668.45275283\n",
      "-144193017.70224437\n",
      "-144247303.2580154\n",
      "-144301525.71178615\n",
      "-144355685.65270293\n",
      "-144409783.6673197\n",
      "-144463820.33957812\n",
      "-144517796.25080565\n",
      "-144571711.97968322\n",
      "-144625568.10223153\n",
      "-144679365.19180837\n",
      "-144733103.81907833\n",
      "-144786784.5520045\n",
      "-144840407.95583707\n",
      "-144893974.59309494\n",
      "-144947485.02354503\n",
      "-145000939.80419815\n",
      "-145054339.48929724\n",
      "-145107684.63028672\n",
      "-145160975.77581167\n",
      "-145214213.47170642\n",
      "-145267398.260975\n",
      "-145320530.68378058\n",
      "-145373611.27743477\n",
      "-145426640.57637686\n",
      "-145479619.11217636\n",
      "-145532547.4135065\n",
      "-145585426.00614065\n",
      "-145638255.41293916\n",
      "-145691036.1538339\n",
      "-145743768.74583384\n",
      "-145796453.7029876\n",
      "-145849091.5363958\n",
      "-145901682.7541927\n",
      "-145954227.86152995\n",
      "-146006727.36057973\n",
      "-146059181.75051266\n",
      "-146111591.52750963\n",
      "-146163957.1847177\n",
      "-146216279.212281\n",
      "-146268558.09730113\n",
      "-146320794.32384413\n",
      "-146372988.37293246\n",
      "-146425140.72254145\n",
      "-146477251.84757382\n",
      "-146529322.21986926\n",
      "-146581352.30820376\n",
      "-146633342.57826263\n",
      "-146685293.49264473\n",
      "-146737205.51085868\n",
      "-146789079.08931527\n",
      "-146840914.68132183\n",
      "-146892712.73707145\n",
      "-146944473.70366257\n",
      "-146996198.025055\n",
      "-147047886.1420972\n",
      "-147099538.4925094\n",
      "-147151155.51088214\n",
      "-147202737.6286748\n",
      "-147254285.27420175\n",
      "-147305798.87265265\n",
      "-147357278.84606004\n",
      "-147408725.6133202\n",
      "-147460139.59018248\n",
      "-147511521.18924293\n",
      "-147562870.81994912\n",
      "-147614188.88859436\n",
      "-147665475.79832062\n",
      "-147716731.94912148\n",
      "-147767957.737823\n",
      "-147819153.55810392\n",
      "-147870319.80048674\n",
      "-147921456.85233402\n",
      "-147972565.0978545\n",
      "-148023644.91809946\n",
      "-148074696.69096556\n",
      "-148125720.79120776\n",
      "-148176717.59040785\n",
      "-148227687.4570127\n",
      "-148278630.75631315\n",
      "-148329547.85044992\n",
      "-148380439.09842014\n",
      "-148431304.85607484\n",
      "-148482145.47612613\n",
      "-148532961.3081534\n",
      "-148583752.69858617\n",
      "-148634519.99073774\n",
      "-148685263.5247798\n",
      "-148735983.63776046\n",
      "-148786680.66361186\n",
      "-148837354.93314213\n",
      "-148888006.77404734\n",
      "-148938636.5109123\n",
      "-148989244.46522275\n",
      "-149039830.95535827\n",
      "-149090396.29660508\n",
      "-149140940.8011595\n",
      "-149191464.77813318\n",
      "-149241968.53355658\n",
      "-149292452.37039065\n",
      "-149342916.5885293\n",
      "-149393361.4848007\n",
      "-149443787.3529803\n",
      "-149494194.48379105\n",
      "-149544583.16492653\n",
      "-149594953.68102893\n",
      "-149645306.31372717\n",
      "-149695641.3416195\n",
      "-149745959.0403014\n",
      "-149796259.68235064\n",
      "-149846543.5373578\n",
      "-149896810.87191567\n",
      "-149947061.94964406\n",
      "-149997297.03118154\n",
      "-150047516.37421048\n",
      "-150097720.23344934\n",
      "-150147908.86067617\n",
      "-150198082.50473097\n",
      "-150248241.41152143\n",
      "-150298385.82403627\n",
      "-150348515.98236084\n",
      "-150398632.12367475\n",
      "-150448734.48227006\n",
      "-150498823.2895592\n",
      "-150548898.77408338\n",
      "-150598961.1615311\n",
      "-150649010.6747325\n",
      "-150699047.5336907\n",
      "-150749071.95557824\n",
      "-150799084.1547524\n",
      "-150849084.34276852\n",
      "-150899072.7283833\n",
      "-150949049.517581\n",
      "-150999014.9135704\n",
      "-151048969.11680132\n",
      "-151098912.32498896\n",
      "-151148844.73311156\n",
      "-151198766.53341687\n",
      "-151248677.91546148\n",
      "-151298579.06609264\n",
      "-151348470.16948402\n",
      "-151398351.40713844\n",
      "-151448222.95790488\n",
      "-151498084.99798396\n",
      "-151547937.700956\n",
      "-151597781.23777983\n",
      "-151647615.7768135\n",
      "-151697441.48383367\n",
      "-151747258.52203602\n",
      "-151797067.05206138\n",
      "-151846867.23201063\n",
      "-151896659.21744454\n",
      "-151946443.16142523\n",
      "-151996219.21449623\n",
      "-152045987.52472216\n",
      "-152095748.2377101\n",
      "-152145501.49659577\n",
      "-152195247.4420739\n",
      "-152244986.21244\n",
      "-152294717.9435548\n",
      "-152344442.7688993\n",
      "-152394160.8195762\n",
      "-152443872.22432598\n",
      "-152493577.1095515\n",
      "-152543275.59932357\n",
      "-152592967.81539598\n",
      "-152642653.87724012\n",
      "-152692333.90204126\n",
      "-152742008.00472766\n",
      "-152791676.2979752\n",
      "-152841338.89224505\n",
      "-152890995.8957799\n",
      "-152940647.41463384\n",
      "-152990293.5526774\n",
      "-153039934.41163534\n",
      "-153089570.09108567\n",
      "-153139200.6884796\n",
      "-153188826.29916945\n",
      "-153238447.01642013\n",
      "-153288062.931421\n",
      "-153337674.13331836\n",
      "-153387280.70921886\n",
      "-153436882.7442162\n",
      "-153486480.32140696\n",
      "-153536073.52190918\n",
      "-153585662.42487857\n",
      "-153635247.10753506\n",
      "-153684827.64516908\n",
      "-153734404.11116633\n",
      "-153783976.5770283\n",
      "-153833545.11239505\n",
      "-153883109.78504753\n",
      "-153932670.6609388\n",
      "-153982227.80421257\n",
      "-154031781.2772264\n",
      "-154081331.14055377\n",
      "-154130877.45301393\n",
      "-154180420.27170235\n",
      "-154229959.6519856\n",
      "-154279495.6475345\n",
      "-154329028.31034732\n",
      "-154378557.69075638\n",
      "-154428083.8374552\n",
      "-154477606.79751584\n",
      "-154527126.61640757\n",
      "-154576643.338016\n",
      "-154626157.00466225\n",
      "-154675667.65711975\n",
      "-154725175.33464155\n",
      "-154774680.07496694\n",
      "-154824181.9143487\n",
      "-154873680.88756797\n",
      "-154923177.0279593\n",
      "-154972670.36742535\n",
      "-155022160.93645173\n",
      "-155071648.76413202\n",
      "-155121133.87818456\n",
      "-155170616.30496895\n",
      "-155220096.0695131\n",
      "-155269573.19551748\n",
      "-155319047.70539004\n",
      "-155368519.62025046\n",
      "-155417988.95995688\n",
      "-155467455.74312\n",
      "-155516919.98712996\n",
      "-155566381.7081618\n",
      "-155615840.92120224\n",
      "-155665297.6400656\n",
      "-155714751.87741196\n",
      "-155764203.64476472\n",
      "-155813652.9525289\n",
      "-155863099.81000867\n",
      "-155912544.225425\n",
      "-155961986.2059312\n",
      "-156011425.7576387\n",
      "-156060862.88562176\n",
      "-156110297.59394348\n",
      "-156159729.88567036\n",
      "-156209159.7628897\n",
      "-156258587.22672617\n",
      "-156308012.2773591\n",
      "-156357434.9140367\n",
      "-156406855.1351009\n",
      "-156456272.9379916\n",
      "-156505688.31927106\n",
      "-156555101.27463818\n",
      "-156604511.79894242\n",
      "-156653919.88620368\n",
      "-156703325.52963254\n",
      "-156752728.72162697\n",
      "-156802129.45381078\n",
      "-156851527.71703243\n",
      "-156900923.50138444\n",
      "-156950316.79623067\n",
      "-156999707.59020498\n",
      "-157049095.87122995\n",
      "-157098481.6265356\n",
      "-157147864.8426723\n",
      "-157197245.5055245\n",
      "-157246623.6003253\n",
      "-157295999.11167043\n",
      "-157345372.0235319\n",
      "-157394742.31927228\n",
      "-157444109.98165762\n",
      "-157493474.9928712\n",
      "-157542837.33452296\n",
      "-157592196.9876785\n",
      "-157641553.93284756\n",
      "-157690908.15001145\n",
      "-157740259.6186396\n",
      "-157789608.31768966\n",
      "-157838954.2256281\n",
      "-157888297.32044044\n",
      "-157937637.57964295\n",
      "-157986974.98029494\n",
      "-158036309.49900994\n",
      "-158085641.11196762\n",
      "-158134969.79492497\n",
      "-158184295.52322555\n",
      "-158233618.27181867\n",
      "-158282938.01525804\n",
      "-158332254.72771662\n",
      "-158381568.38300943\n",
      "-158430878.95458567\n",
      "-158480186.41554898\n",
      "-158529490.7386679\n",
      "-158578791.89637524\n",
      "-158628089.860799\n",
      "-158677384.6037507\n",
      "-158726676.0967437\n",
      "-158775964.31101054\n",
      "-158825249.21749377\n",
      "-158874530.7868653\n",
      "-158923808.98954767\n",
      "-158973083.7956918\n",
      "-159022355.1752271\n",
      "-159071623.09782836\n",
      "-159120887.53294927\n",
      "-159170148.4498222\n",
      "-159219405.81747037\n",
      "-159268659.60472\n",
      "-159317909.78019145\n",
      "-159367156.31231937\n",
      "-159416399.1693645\n",
      "-159465638.31940454\n",
      "-159514873.73036593\n",
      "-159564105.37000018\n",
      "-159613333.2059201\n",
      "-159662557.20559373\n",
      "-159711777.33633527\n",
      "-159760993.56535438\n",
      "-159810205.85971576\n",
      "-159859414.18637234\n",
      "-159908618.51216716\n",
      "-159957818.80383158\n",
      "-160007015.02800387\n",
      "-160056207.15122646\n",
      "-160105395.1399562\n",
      "-160154578.960564\n",
      "-160203758.5793443\n",
      "-160252933.9625252\n",
      "-160302105.0762691\n",
      "-160351271.88667256\n",
      "-160400434.35978138\n",
      "-160449592.4615897\n",
      "-160498746.15805915\n",
      "-160547895.41509548\n",
      "-160597040.19856948\n",
      "-160646180.47434056\n",
      "-160695316.20822594\n",
      "-160744447.36602217\n",
      "-160793573.9135158\n",
      "-160842695.8164791\n",
      "-160891813.04067475\n",
      "-160940925.5518704\n",
      "-160990033.31581977\n",
      "-161039136.2982961\n",
      "-161088234.46507084\n",
      "-161137327.78193665\n",
      "-161186416.21469843\n",
      "-161235499.72917747\n",
      "-161284578.2912252\n",
      "-161333651.86671662\n",
      "-161382720.42156407\n",
      "-161431783.92170832\n",
      "-161480842.33313042\n",
      "-161529895.62185478\n",
      "-161578943.75394046\n",
      "-161627986.69551268\n",
      "-161677024.41273573\n",
      "-161726056.87182367\n",
      "-161775084.0390624\n",
      "-161824105.88078552\n",
      "-161873122.36339188\n",
      "-161922133.4533524\n",
      "-161971139.11720058\n",
      "-162020139.3215435\n",
      "-162069134.0330605\n",
      "-162118123.2185116\n",
      "-162167106.84473646\n",
      "-162216084.87865222\n",
      "-162265057.28726074\n",
      "-162314024.03765675\n",
      "-162362985.09701797\n",
      "-162411940.4326137\n",
      "-162460890.01180905\n",
      "-162509833.80207154\n",
      "-162558771.77095625\n",
      "-162607703.88611692\n",
      "-162656630.11532795\n",
      "-162705550.4264499\n",
      "-162754464.78745386\n",
      "-162803373.16642553\n",
      "-162852275.5315549\n",
      "-162901171.8511462\n",
      "-162950062.09361768\n",
      "-162998946.22750354\n",
      "-163047824.22145545\n",
      "-163096696.04424262\n",
      "-163145561.66475913\n",
      "-163194421.05202162\n",
      "-163243274.17516488\n",
      "-163292121.0034576\n",
      "-163340961.50628954\n",
      "-163389795.65318123\n",
      "-163438623.41378337\n",
      "-163487444.75787824\n",
      "-163536259.65538096\n",
      "-163585068.07634097\n",
      "-163633869.9909411\n",
      "-163682665.36950707\n",
      "-163731454.18249646\n",
      "-163780236.40050796\n",
      "-163829011.99428064\n",
      "-163877780.93469498\n",
      "-163926543.19277173\n",
      "-163975298.73968145\n",
      "-164024047.5467328\n",
      "-164072789.58538225\n",
      "-164121524.8272324\n",
      "-164170253.24403322\n",
      "-164218974.80768287\n",
      "-164267689.4902284\n",
      "-164316397.2638647\n",
      "-164365098.10094327\n",
      "-164413791.97396064\n",
      "-164462478.8555654\n",
      "-164511158.7185648\n",
      "-164559831.53591126\n",
      "-164608497.28071713\n",
      "-164657155.9262491\n",
      "-164705807.44592458\n",
      "-164754451.81331885\n",
      "-164803089.00216264\n",
      "-164851718.9863391\n",
      "-164900341.73989657\n",
      "-164948957.2370401\n",
      "-164997565.45212203\n",
      "-165046166.35966265\n",
      "-165094759.93433005\n",
      "-165143346.15096515\n",
      "-165191924.98455253\n",
      "-165240496.41024402\n",
      "-165289060.40335\n",
      "-165337616.93933573\n",
      "-165386165.99382555\n",
      "-165434707.54260892\n",
      "-165483241.56162828\n",
      "-165531768.0269851\n",
      "-165580286.91494608\n",
      "-165628798.2019307\n",
      "-165677301.8645153\n",
      "-165725797.87944525\n",
      "-165774286.22361633\n",
      "-165822766.87408656\n",
      "-165871239.80806625\n",
      "-165919705.0029319\n",
      "-165968162.43621123\n",
      "-166016612.08558962\n",
      "-166065053.92891553\n",
      "-166113487.94418573\n",
      "-166161914.10955977\n",
      "-166210332.40335068\n",
      "-166258742.80402905\n",
      "-166307145.2902162\n",
      "-166355539.8406902\n",
      "-166403926.43438262\n",
      "-166452305.05037662\n",
      "-166500675.66791213\n",
      "-166549038.2663771\n",
      "-166597392.82531905\n",
      "-166645739.32442623\n",
      "-166694077.74353886\n",
      "-166742408.06265283\n",
      "-166790730.2619045\n",
      "-166839044.3215842\n",
      "-166887350.2221294\n",
      "-166935647.9441195\n",
      "-166983937.46827957\n",
      "-167032218.77548522\n",
      "-167080491.84674957\n",
      "-167128756.66323036\n",
      "-167177013.20622724\n",
      "-167225261.45717847\n",
      "-167273501.39766842\n",
      "-167321733.00941178\n",
      "-167369956.27426523\n",
      "-167418171.1742282\n",
      "-167466377.69142535\n",
      "-167514575.80811998\n",
      "-167562765.50670877\n",
      "-167610946.76972044\n",
      "-167659119.57981282\n",
      "-167707283.91977978\n",
      "-167755439.7725353\n",
      "-167803587.1211272\n",
      "-167851725.94872922\n",
      "-167899856.2386359\n",
      "-167947977.97426546\n",
      "-167996091.1391645\n",
      "-168044195.71699435\n",
      "-168092291.69153795\n",
      "-168140379.04669672\n",
      "-168188457.7664888\n",
      "-168236527.83504784\n",
      "-168284589.2366196\n",
      "-168332641.95556659\n",
      "-168380685.97636268\n",
      "-168428721.2835872\n",
      "-168476747.86193\n",
      "-168524765.69618788\n",
      "-168572774.77125886\n",
      "-168620775.07215732\n",
      "-168668766.5839855\n",
      "-168716749.29195684\n",
      "-168764723.18137786\n",
      "-168812688.23765522\n",
      "-168860644.44629163\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[ 0.63818572],\n        [ 0.73790155],\n        [ 4.41232174],\n        [ 0.54344366],\n        [ 0.62625579],\n        [ 4.27469195],\n        [ 0.62106536],\n        [ 4.01394069],\n        [-4.22131497],\n        [ 0.64910718],\n        [-4.32593986],\n        [-4.23122883],\n        [ 4.23060491],\n        [ 0.568943  ],\n        [ 0.64757266],\n        [ 0.54498773],\n        [ 0.66202854],\n        [ 4.11549196],\n        [-4.01261825],\n        [ 4.02847059]]),\n array([[1.05238927],\n        [1.43764097],\n        [2.1334054 ],\n        ...,\n        [0.31904119],\n        [1.08720064],\n        [1.53572402]]),\n array([[1.39004565e-20, 2.50612939e-28, 6.31049329e-43, ...,\n         6.04155467e-04, 1.00000000e+00, 1.00000000e+00],\n        [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, ...,\n         9.99395845e-01, 6.15033980e-21, 3.07805998e-30]]))"
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha, beta, q = em(L)\n",
    "alpha, beta, q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 2. (1 балл)** Загрузите настоящую разметку. Посчитайте `accuracy` разметки, полученной с помощью обычного голосования по большинству среди экспертов, и сравните его с качеством, полученным с помощью EM-алгоритма. Помните, что алгоритму не важно, какая метка 0, а какая 1, поэтому если получите качество <0.5, то просто поменяйте метки классов (не забудьте также поменять знак у $\\alpha$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = np.load('y.npy')\n",
    "# (∩ ￣ー￣)⊃ ✳✨✳✨✳✨✳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ True,  True,  True, ..., False, False, False])"
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = np.sum(L, axis=1) / m > 0.5\n",
    "voting_clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting clf accuracy: 0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'voting clf accuracy: {accuracy_score(y, voting_clf)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, ..., 1, 0, 0])"
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_clf = np.argmax(q, axis = 0)\n",
    "em_clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em clf accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "print(f'em clf accuracy: {accuracy_score(y, em_clf)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 3. (0.5 балла)** Попробуйте проинтерпретировать полученные коэфициенты $\\alpha$. Есть ли в выборке эксперты, которые намеренно голосуют неверно? Как это можно понять по альфам? Продемонстрируйте, что эксперты действительно чаще голосуют за неверный класс. Постройте график зависимости доли врено размеченных экспертом объектов от коэффициента $\\alpha$. Прокомментируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (∩ᄑ_ᄑ)⊃━☆ﾟ*･｡*\n",
    "y = y.reshape(-1,1)\n",
    "ratio = np.sum(1 - np.abs(L - y), axis=0)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 500x400 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,4), dpi=100)\n",
    "plt.scatter(x = alpha, y = ratio)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('ratio')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "эксперты с alpha < 0 чаще выбирают неверный класс - это видно из графика сверху\n",
    "экспервы с alpha > 1 имеют близкую к единице долю верно размеченных задач"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 4. (бонус, 2 балла)**  Как уже было замечено выше, модели не важно, какой класс 1, а какой 0. Скажем, если все эксперты оказались максимально противными и ставят метку с точностью наоборот, то у вас будет полная согласованность между экспертами, при этом невозможно понять правильно они разметили выборку или нет, смотря только на такую разметку. Чтобы избежать этого, можно включать в выборку вопрос с заведомо известным ответом, тогда вы сможете определить, ставит ли эксперт специально неверные метки.\n",
    "\n",
    "Чтобы обощить данную модель на случай заданий с заведомо известной меткой, достоточно не делать для них E-шаг, а всегда полагать апостериорное распределение вырожденным в истинном классе. Реализуйте данную модель и используйте истинную разметку *для нескольких* задач из обучения. Проинтерпретируйте полученные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Выравнивание слов (Word Alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "EM-алгоритм также применяют на практике для настройки параметров модели выравнивания слов, более сложные модификации которой используются в статистическом машинном переводе. Мы не будем подробно обсуждать применение word alignment для перевода и ограничимся следующей целью: пусть у нас есть параллельный корпус из предложений на исходном языке и их переводов на целевой язык (в этом задании используются английский и чешский соответственно). \n",
    "\n",
    "Первая задача — определить с помощью этого корпуса, как переводится каждое отдельное слово на целевом языке. Вторая задача — для произвольной пары из предложения и его перевода установить, переводом какого слова в исходном предложении является каждое слово в целевом предложении. Оказывается, у обеих задач существует элегантное и эффективное решение при введении правильной вероятностной модели: в этой части задания вам предстоит его реализовать и оценить результаты работы. Но обо всём по порядку :)\n",
    "\n",
    "---\n",
    "\n",
    "Перед тем, как заниматься машинным обучением, давайте разберёмся с данными и метриками в интересующей нас задаче. В ячейке ниже загружается и разархивируется параллельный английско-чешский корпус, в котором есть разметка выравнивания слов. Нетрудно заметить, что формат XML-файла, использованный его авторами, не вполне стандартный: нет готовой команды , которая позволила бы получить список пар предложений вместе с выравниваниями. Это значит, что нужно разобраться с форматом и написать парсер самостоятельно, используя встроенные средства Python, например, модуль [xml](https://docs.python.org/3.7/library/xml.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n",
      "<sentences>\n",
      "<s id=\"project_syndicate_bacchetta1-s1\">\r\n",
      "  <english>Are the Dollar 's Days Numbered ?</english>\n",
      "  <czech>Jsou dny dolaru sečteny ?</czech>\n",
      "  <sure>1-1 3-3 5-2 6-4 7-5</sure>\n",
      "  <possible>2-2 4-3</possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s2\">\r\n",
      "  <english>Philippe Bacchetta and Eric van Wincoop</english>\n",
      "  <czech>Philippe Bacchetta and Eric van Wincoop</czech>\n",
      "  <sure>1-1 2-2 3-3 4-4 5-5 6-6</sure>\n",
      "  <possible></possible>\n",
      "</s>\n",
      "<s id=\"project_syndicate_bacchetta1-s3\">\r\n",
      "  <english>A year ago , the dollar bestrode the world like a colossus .</english>\n",
      "  <czech>Ještě před rokem dolar dominoval světu jako imperátor .</czech>\n",
      "  <sure>10-7 12-8 13-9 2-3 3-2 6-4 7-5 9-6</sure>\n",
      "  <possible>1-3 11-8 3-1 5-4 8-6</possible>\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget -q https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-1804/CzEnAli_1.0.tar.gz -O CzEnAli_1.0.tar.gz\n",
    "mkdir -p data\n",
    "tar -xzf CzEnAli_1.0.tar.gz -C data/\n",
    "head -n 20 data/merged_data/project_syndicate/project_syndicate_bacchetta1.wa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание -2. (0.5 балла)** Реализуйте функцию `extract_sentences`, которая принимает на вход путь к файлу с XML-разметкой, используемой в этом датасете, и возвращает список параллельных предложений, а также список из «уверенных» (sure) и «возможных» (possible) пар выравниваний. Отправьте вашу реализацию в Яндекс.Контест, чтобы убедиться в её корректности; в следующей ячейке ноутбука соберите все пары размеченных предложений из датасета в два списка `all_sentences` (список `SentencePair`) и `all_targets` (список LabeledAlignment).\n",
    "\n",
    "Здесь и далее соблюдайте сигнатуры функций и пользуйтесь объявленными в модуле `preprocessing.py` классами для организации данных. Стоит заметить, что предложения уже токенизированы (даже отделена пунктуация), поэтому предобработку текстов совершать не нужно. Обратите внимание на формат хранения выравниваний: нумерация начинается с 1 (в таком виде и нужно сохранять), первым в паре идёт слово из англоязычного предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "import glob\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "([SentencePair(source=['this', 'is', 'the', 'reason', 'secretary', 'of', 'state', 'condoleezza', 'rice', 'was', 'cautious', 'in', 'her', 'reaction', 'to', 'the', 'saudis', \"'\", 'ambiguous', 'acceptance', 'of', 'their', 'invitation', 'to', 'attend', 'the', 'conference'], target=['právě', 'z', 'toho', 'důvodu', 'se', 'ministryně', 'zahraničí', 'condoleezza', 'riceová', 'vyjádřila', 've', 'své', 'reakci', 'na', 'nejednoznačný', 'souhlas', 'saúdů', 's', 'účastí', 'na', 'konferenci', 'tak', 'obezřetně']),\n  SentencePair(source=['the', 'syria', 'iran', 'hamas', 'hezbollah', 'axis', 'would', 'be', 'emboldened', 'in', 'its', 'challenge', 'to', 'american', 'leadership', 'in', 'the', 'region', 'and', 'with', 'palestinian', 'president', 'mahmoud', 'abbas', 'humbled', 'and', 'defeated', 'a', 'third', 'intifada', 'would', 'be', 'a', 'likely', 'scenario'], target=['osu', 'sýrie', 'írán', 'hamás', 'hizballáh', 'by', 'povzbudil', 'v', 'napadání', 'americké', 'vůdčí', 'úlohy', 'v', 'regionu', 'a', 'poněvadž', 'palestinský', 'prezident', 'mahmúd', 'abbás', 'by', 'byl', 'pokořen', 'a', 'poražen', 'pravděpodobným', 'scénářem', 'by', 'byla', 'třetí', 'intifáda']),\n  SentencePair(source=['it', 'is', 'therefore', 'vitally', 'important', 'to', 'take', 'syria', 'an', 'ally', 'of', 'iran', 'and', 'the', 'patron', 'of', 'spoilers', 'such', 'as', 'hamas', 'and', 'hezbollah', 'out', 'of', 'the', 'war', 'equation'], target=['je', 'tedy', 'nesmírně', 'důležité', 'z', 'válečné', 'rovnice', 'odebrat', 'sýrii', 'spojence', 'íránu', 'a', 'podporovatele', 'záškodníků', 'jako', 'jsou', 'hamás', 'a', 'hizballáh']),\n  SentencePair(source=['but', 'this', 'requires', 'that', 'both', 'israel', 'and', 'the', 'united', 'states', 'change', 'course'], target=['to', 'ale', 'vyžaduje', 'aby', 'izrael', 'i', 'spojené', 'státy', 'změnily', 'kurz']),\n  SentencePair(source=['last', 'year', 'russia', 'patriarch', 'aleksei', 'gave', 'his', 'blessing', 'to', 'a', 'visit', 'to', 'moscow', 'by', 'the', 'catholic', 'girls', \"'\", 'choir', 'of', 'the', 'saint', 'danilov', 'monastery'], target=['loni', 'ruský', 'patriarcha', 'aleksej', 'požehnal', 'moskevské', 'návštěvě', 'dívčího', 'katolického', 'sboru', 'z', 'kláštera', 'sv', 'danilova']),\n  SentencePair(source=['soon', 'after', 'and', 'more', 'importantly', 'the', 'patriarch', 'raised', 'the', 'level', 'of', 'orthodoxy', 'representation', 'at', 'an', 'ecumenical', 'prayer', 'called', 'by', 'pope', 'john', 'paul', 'ii', 'in', 'assisi', 'on', 'january', '24', 'th'], target=['nedlouho', 'poté', 'došlo', 'k', 'čemusi', 'dalece', 'významnějšímu', 'patriarcha', 'zvedl', 'úroveň', 'zastoupení', 'pravoslavné', 'církve', 'při', 'ekumenické', 'bohoslužbě', 'svolané', 'papežem', 'janem', 'pavlem', 'ii', 'na', '24', 'ledna', 'do', 'assisi']),\n  SentencePair(source=['this', 'was', 'to', 'be', 'followed', 'by', 'a', 'visit', 'to', 'moscow', 'by', 'a', 'senior', 'vatican', 'cleric', 'cardinal', 'walter', 'kasper', 'president', 'of', 'the', 'pontifical', 'council', 'for', 'promoting', 'christian', 'unity', 'and', 'the', 'man', 'who', 'helped', 'organize', 'last', 'year', 'papal', 'visits', 'to', 'ukraine', 'kazakhstan', 'and', 'armenia'], target=['po', 'ní', 'měl', 'do', 'moskvy', 'zavítat', 'vysoký', 'vatikánský', 'duchovní', 'předseda', 'pontifikální', 'rady', 'pro', 'šíření', 'křesťanské', 'jednoty', 'kardinál', 'walter', 'kasper', 'který', 'v', 'loňském', 'roce', 'významně', 'pomáhal', 'při', 'organizaci', 'papežské', 'cesty', 'na', 'ukrajinu', 'do', 'kazachstánu', 'a', 'arménie']),\n  SentencePair(source=['as', 'a', 'frenchman', 'i', 'cannot', 'wait', 'for', 'the', 'next', 'world', 'cup', 'match', 'between', 'france', 'and', 'germany'], target=['já', 'jako', 'francouz', 'se', 'například', 'nemohu', 'dočkat', 'dalšího', 'utkání', 'mezi', 'francií', 'a', 'německem', 'na', 'mistrovství', 'světa']),\n  SentencePair(source=['but', 'i', 'want', 'france', 'to', 'avenge', 'its', 'defeat', 'at', 'the', 'last', 'world', 'cup', 'in', 'seville', 'not', 'its', 'defeat', 'at', 'verdun'], target=['přeji', 'si', 'však', 'aby', 'francie', 'pomstila', 'svou', 'poslední', 'porážku', 'z', 'mistrovství', 'světa', 'v', 'seville', 'nikoliv', 'svou', 'porážku', 'u', 'verdunu']),\n  SentencePair(source=['pascal', 'boniface', 'is', 'director', 'of', 'the', 'institute', 'for', 'international', 'and', 'strategic', 'relations', 'iris', 'paris'], target=['pascal', 'boniface', 'je', 'ředitelem', 'pařížského', 'institutu', 'pro', 'mezinárodní', 'a', 'strategické', 'vztahy', 'iris']),\n  SentencePair(source=['from', 'khrushchev', 'onward', 'moscow', 'rulers', 'eyed', 'the', 'vatican', 'suspiciously', 'but', 'not', 'without', 'interest'], target=['nedůvěřivě', 'ale', 'nikoli', 'bez', 'zájmu', 'sledovali', 'vatikán', 'moskevští', 'mocipáni', 'už', 'od', 'dob', 'chruščova']),\n  SentencePair(source=['kremlin', 'leaders', 'instinctively', 'understood', 'the', 'benefits', 'of', 'normalising', 'relations', 'with', 'the', 'holy', 'see', 'for', 'soviet', 'propaganda', 'and', 'foreign', 'policy', 'and', 'meetings', 'between', 'the', 'pope', 'and', 'andrei', 'gromyko', 'and', 'nikolai', 'podgorny', 'did', 'take', 'place'], target=['kreml', 'instinktivně', 'chápal', 'přínos', 'normalizace', 'vztahů', 'se', 'svatým', 'stolcem', 'pro', 'sovětskou', 'propagandu', 'a', 'zahraniční', 'politiku', 'došlo', 'ostatně', 'ke', 'schůzkám', 'mezi', 'papežem', 'a', 'andrejem', 'gromykem', 'a', 'nikolajem', 'podgornym']),\n  SentencePair(source=['not', 'until', '1989', 'however', 'did', 'mikhail', 'gorbachev', 'dare', 'establish', 'official', 'relations', 'with', 'the', 'vatican', 'inviting', 'pope', 'john', 'paul', 'ii', 'to', 'visit', 'the', 'soviet', 'union'], target=['až', 'v', 'roce', '1989', 'se', 'však', 'michail', 'gorbačov', 'odvážil', 'navázat', 'oficiální', 'vztahy', 's', 'vatikánem', 'a', 'pozvat', 'papeže', 'jana', 'pavla', 'ii', 'na', 'návštěvu', 'sovětského', 'svazu']),\n  SentencePair(source=['indeed', 'brown', 'for', 'whom', 'america', 'remains', 'britain', 'most', 'important', 'bilateral', 'relationship', 'recently', 'blocked', 'his', 'foreign', 'secretary', 'david', 'miliband', 'from', 'delivering', 'a', 'speech', 'that', 'he', 'considered', 'excessively', 'pro', 'europe'], target=['brown', 'pro', 'něhož', 'amerika', 'zůstává', 'nejvýznamnějším', 'britským', 'bilaterálním', 'vztahem', 'nedávno', 'svému', 'ministru', 'zahraničí', 'davidu', 'milibandovi', 'znemožnil', 'aby', 'pronesl', 'řeč', 'již', 'považoval', 'za', 'příliš', 'proevropskou']),\n  SentencePair(source=['but', 'such', 'uncertainty', 'common', 'in', 'times', 'of', 'transition', 'should', 'not', 'overshadow', 'what', 'the', 'end', 'of', 'the', 'blair', 'bush', 'era', 'in', 'britain', 'holds', 'in', 'store'], target=['taková', 'nejistota', 'v', 'transformačních', 'dobách', 'obvyklá', 'by', 'ale', 'neměla', 'zastínit', 'co', 'konec', 'éry', 'spojenectví', 'blair', 'bush', 'v', 'británii', 'přináší']),\n  SentencePair(source=['unilateralism', 'and', 'pre', 'emptive', 'wars', 'are', 'to', 'be', 'replaced', 'by', 'what', 'brown', 'defines', 'as', 'an', 'agenda', 'for', 'a', 'hard', 'headed', 'internationalism', 'based', 'on', 'cooperation', 'with', 'multilateral', 'agencies', 'and', 'alliances', 'the', 'united', 'nations', 'nato', 'the', 'european', 'union', 'and', 'the', 'british', 'commonwealth'], target=['unilateralismus', 'a', 'preemptivní', 'války', 'vystřídá', 'to', 'co', 'brown', 'definuje', 'jako', 'agenda', 'pro', 'střízlivý', 'internacionalismus', 'založená', 'na', 'spolupráci', 's', 'multilaterálními', 'agenturami', 'a', 'aliancemi', 'organizací', 'spojených', 'národů', 'nato', 'evropskou', 'unií', 'a', 'britským', 'společenstvím', 'commonwealth']),\n  SentencePair(source=['a', 'democracy', 'that', 'produces', 'governments', 'led', 'by', 'hamas', 'hezbollah', 'or', 'the', 'muslim', 'brotherhood', 'is', 'inevitably', 'bound', 'to', 'be', 'anti', 'western', 'and', 'opposed', 'to', 'an', 'american', 'inspired', 'peace', 'process', 'with', 'israel'], target=['demokracie', 'jejímiž', 'plody', 'jsou', 'vlády', 'vedené', 'hamásem', 'hizballáhem', 'či', 'muslimským', 'bratrstvem', 'bude', 'nevyhnutelně', 'protizápadní', 'a', 'bude', 'se', 'stavět', 'proti', 'američany', 'vštěpovanému', 'mírovému', 'procesu', 's', 'izraelem']),\n  SentencePair(source=['syria', 'has', 'already', 'sought', 'to', 'assure', 'regime', 'continuity', 'through', 'quasi', 'monarchic', 'hereditary', 'succession', 'with', 'the', 'move', 'from', 'hafez', 'al', 'assad', 'to', 'his', 'son', 'bashar'], target=['zajistit', 'kontinuitu', 'režimu', 'prostřednictvím', 'kvazimonarchického', 'dědičného', 'následnictví', 'se', 'už', 'pokusila', 'sýrie', 'když', 'došlo', 'k', 'přechodu', 'od', 'háfize', 'al', 'asada', 'k', 'jeho', 'synu', 'bašárovi']),\n  SentencePair(source=['there', 'are', 'indications', 'that', 'egypt', 'might', 'follow', 'suit', 'with', 'hosni', 'mubarak', 'son', 'gamal', 'taking', 'over'], target=['existují', 'náznaky', 'že', 'by', 'příkladu', 'mohl', 'následovat', 'egypt', 'kde', 'by', 'moc', 'převzal', 'syn', 'husního', 'mubáraka', 'gamál']),\n  SentencePair(source=['but', 'prying', 'syria', 'from', 'iran', 'embrace', 'means', 'eventually', 'reopening', 'the', 'golan', 'heights', 'question'], target=['vyrvat', 'sýrii', 'z', 'íránského', 'objetí', 'však', 'v', 'konečném', 'důsledku', 'znamená', 'znovuotevřít', 'otázku', 'golanských', 'výšin']),\n  SentencePair(source=['a', 'deal', 'with', 'syria', 'is', 'not', 'impossible', 'given', 'the', 'ambiguities', 'in', 'assad', 'position'], target=['vzhledem', 'k', 'nejednoznačnosti', 'asadovy', 'pozice', 'není', 'dohoda', 'se', 'sýrií', 'nemožná']),\n  SentencePair(source=['on', 'the', 'israeli', 'american', 'side', 'it', 'would', 'include', 'recognition', 'that', 'syria', 'has', 'security', 'interests', 'in', 'lebanon'], target=['na', 'straně', 'izraele', 'a', 'spojených', 'států', 'by', 'zahrnovala', 'uznání', 'že', 'sýrie', 'má', 'v', 'libanonu', 'bezpečnostní', 'zájmy']),\n  SentencePair(source=['today', 'difficulties', 'in', 'the', 'united', 'states', 'have', 'exacted', 'a', 'heavy', 'toll', 'on', 'growth', 'in', 'latin', 'america'], target=['dnešní', 'potíže', 've', 'spojených', 'státech', 'si', 'v', 'latinské', 'americe', 'vynucují', 'vyšší', 'daň', 'za', 'ekonomický', 'růst']),\n  SentencePair(source=['mexico', 'with', 'most', 'of', 'its', 'exports', 'destined', 'for', 'north', 'america', 'is', 'now', 'in', 'recession'], target=['mexiko', 'jehož', 'exportní', 'většina', 'je', 'určená', 'pro', 'severní', 'ameriku', 'nyní', 'prožívá', 'recesi']),\n  SentencePair(source=['thus', 'growth', 'in', 'asia', 'and', 'latin', 'america', 'depends', 'not', 'only', 'on', 'sound', 'domestic', 'policies', 'but', 'also', 'on', 'what', 'happens', 'elsewhere'], target=['ekonomický', 'růst', 'v', 'asii', 'a', 'latinské', 'americe', 'tedy', 'nezáleží', 'pouze', 'na', 'domácí', 'politice', 'záleží', 'i', 'na', 'tom', 'co', 'se', 'děje', 'jinde']),\n  SentencePair(source=['germany', 'and', 'france', 'were', 'against', 'meeting', 'saddam', 'hussein', 'with', 'military', 'force', 'but', 'had', 'no', 'alternative', 'for', 'getting', 'rid', 'of', 'the', 'butcher', 'of', 'baghdad'], target=['německo', 'a', 'francie', 'byly', 'proti', 'použití', 'vojenské', 'síly', 'vůči', 'saddámu', 'husajnovi', 'ale', 'nenabízely', 'jinou', 'možnost', 'jak', 'bagdádského', 'řezníka', 'odstranit']),\n  SentencePair(source=['what', 'was', 'the', 'european', 'answer', 'to', 'the', 'problem', 'of', 'saddam', 'hussein', 'asked', 'senator', 'joe', 'biden', 'in', 'a', 'panel', 'discussion', 'at', 'the', 'recent', 'davos', 'forum'], target=['jak', 'zněla', 'evropská', 'odpověď', 'na', 'problém', 'saddáma', 'husajna', 'ptal', 'se', 'senátor', 'joe', 'biden', 'v', 'panelové', 'diskusi', 'na', 'nedávném', 'davoském', 'fóru']),\n  SentencePair(source=['biden', 'is', 'a', 'democrat', 'and', 'strong', 'critic', 'of', 'president', 'bush'], target=['biden', 'je', 'člen', 'demokratické', 'strany', 'a', 'ostrý', 'kritik', 'prezident', 'bushe']),\n  SentencePair(source=['once', 'president', 'valéry', 'giscard', 'd', \"'\", 'estaing', 'and', 'federal', 'chancellor', 'helmut', 'schmidt', 'made', 'the', 'joint', 'franco', 'german', 'proposal', 'for', 'the', 'economic', 'and', 'monetary', 'union', 'emu', 'both', 'belgium', 'and', 'the', 'netherlands', 'worked', 'together', 'to', 'achieve', 'that', 'common', 'goal'], target=['jakmile', 'prezident', 'valéry', 'giscard', 'd', \"'\", 'estaing', 'a', 'federální', 'kancléř', 'helmut', 'schmidt', 'přednesli', 'společný', 'francouzsko', 'německý', 'návrh', 'hospodářské', 'a', 'měnové', 'unie', 'hmu', 'belgie', 'a', 'nizozemsko', 've', 'shodě', 'pracovaly', 'na', 'dosažení', 'společného', 'cíle']),\n  SentencePair(source=['along', 'with', 'luxembourg', 'they', 'were', 'an', 'important', 'factor', 'in', 'creating', 'emu'], target=['společně', 's', 'lucemburskem', 'byly', 'významným', 'činitelem', 'vytvoření', 'hmu']),\n  SentencePair(source=['in', '1991', 'when', 'the', 'netherlands', 'held', 'the', 'european', 'presidency', 'belgium', 'supported', 'its', 'far', 'reaching', 'draft', 'for', 'a', 'treaty', 'of', 'european', 'union'], target=['v', 'roce', '1991', 'kdy', 'nizozemsko', 'zastávalo', 'evropské', 'předsednictví', 'belgie', 'podpořila', 'jeho', 'dalekosáhlý', 'návrh', 'smlouvy', 'o', 'evropské', 'unii']),\n  SentencePair(source=['washington', 'dc', 'i', 'have', 'no', 'personal', 'opinion', 'on', 'the', 'virtues', 'of', 'caio', 'koch', 'weiser', 'germany', 'candidate', 'to', 'head', 'the', 'international', 'monetary', 'fund'], target=['washington', 'na', 'caia', 'koch', 'weisera', 'německého', 'kandidáta', 'na', 'vedení', 'mezinárodního', 'měnového', 'fondu', 'nemám', 'dosud', 'žádný', 'názor']),\n  SentencePair(source=['but', 'dithering', 'over', 'michel', 'camdessus', 'replacement', 'ought', 'to', 'stop'], target=['váhání', 'ohledně', 'nástupce', 'michela', 'camdessuse', 'musí', 'ale', 'rozhodně', 'skončit', 'co', 'nejdříve']),\n  SentencePair(source=['stanley', 'fischer', 'a', 'brilliant', 'experienced', 'economist', 'will', 'lead', 'the', 'fund', 'very', 'well', 'in', 'the', 'interim'], target=['prozatím', 'je', 'jisté', 'že', 'stanley', 'fischer', 'vynikající', 'a', 'zkušený', 'ekonom', 'bude', 'fond', 'dočasně', 'řídit', 'velice', 'dobře']),\n  SentencePair(source=['but', 'kennedy', 'was', 'anxious', 'about', 'the', 'consequences', 'of', 'having', 'soviet', 'missiles', 'in', 'cuba', 'on', 'berlin'], target=['kennedyho', 'ale', 'zneklidňovaly', 'důsledky', 'jež', 'by', 'sovětské', 'hlavice', 'na', 'kubě', 'mohly', 'mít', 'pro', 'berlín']),\n  SentencePair(source=['nuclear', 'pressures', 'from', 'cuba', 'would', 'have', 'made', 'defense', 'of', 'berlin', 'more', 'difficult', 'which', 'was', 'part', 'of', 'khrushchev', 'strategy'], target=['jaderný', 'tlak', 'z', 'kuby', 'by', 'totiž', 'ztížil', 'obranu', 'berlína', 'což', 'byla', 'část', 'chruščovovy', 'strategie']),\n  SentencePair(source=['in', 'the', 'end', 'the', 'berlin', 'crisis', 'was', 'solved', 'through', 'the', 'outcome', 'of', 'the', 'cuban', 'missile', 'crisis', 'the', 'historian', 'ernest', 'may', 'argued'], target=['nakonec', 'však', 'podle', 'historika', 'ernesta', 'maye', 'berlínskou', 'krizi', 'vyřešil', 'výsledek', 'kubánské', 'raketové', 'krize']),\n  SentencePair(source=['and', 'kosovo', 'albanian', 'population', 'is', 'clamoring', 'for', 'independence', 'while', 'serbia', 'tries', 'to', 'postpone', 'a', 'decision', 'by', 'blocking', 'action', 'in', 'the', 'security', 'council'], target=['albánské', 'obyvatelstvo', 'kosova', 'se', 'dožaduje', 'nezávislosti', 'zatímco', 'srbsko', 'se', 'snaží', 'rozhodnutí', 'zdržet', 'a', 'blokuje', 'jednání', 'v', 'radě', 'bezpečnosti']),\n  SentencePair(source=['similarly', 'any', 'move', 'by', 'bosnia', 'serb', 'republic', 'to', 'secede', 'could', 'incite', 'instability', 'there'], target=['podobně', 'by', 'v', 'bosně', 'mohl', 'vyvolat', 'nestabilitu', 'jakýkoli', 'krok', 'bosenské', 'republiky', 'srbské', 'k', 'odštěpení']),\n  SentencePair(source=['serbia', 'which', 'traded', 'violent', 'nationalism', 'for', 'nonviolent', 'nationalism', 'when', 'slobodan', 'milosevic', 'was', 'overthrown', 'eight', 'years', 'ago', 'has', 'done', 'all', 'it', 'can', 'to', 'impede', 'resolution', 'of', 'these', 'issues', 'with', 'strong', 'support', 'from', 'vladimir', 'putin', 'russia'], target=['srbsko', 'jež', 'po', 'svržení', 'slobodana', 'miloševiće', 'před', 'osmi', 'lety', 'vyměnilo', 'násilný', 'nacionalismus', 'za', 'nacionalismus', 'nenásilný', 'udělalo', 'vše', 'pro', 'to', 'aby', 'řešení', 'těchto', 'otázek', 'brzdilo', 'za', 'silné', 'podpory', 'ruska', 'vladimíra', 'putina']),\n  SentencePair(source=['serbia', 'wants', 'as', 'much', 'independence', 'as', 'possible', 'for', 'the', 'serb', 'republic', 'while', 'asserting', 'its', 'own', 'sovereignty', 'over', 'kosovo'], target=['srbsko', 'chce', 'maximum', 'nezávislosti', 'pro', 'republiku', 'srbskou', 'zároveň', 'ale', 'prosazuje', 'vlastní', 'svrchovanost', 'nad', 'kosovem']),\n  SentencePair(source=['serbs', 'governed', 'only', 'by', 'serbs', 'on', 'their', 'own', 'territory', 'is', 'still', 'serbia', 'goal'], target=['srbským', 'cílem', 'stále', 'jsou', 'srbové', 'pod', 'vládou', 'srbů', 'na', 'svém', 'vlastním', 'území']),\n  SentencePair(source=['the', 'united', 'states', 'and', 'the', 'european', 'union', 'are', 'committed', 'to', 'a', 'different', 'vision', 'democratic', 'transition', 'and', 'integration', 'of', 'all', 'of', 'the', 'balkans', 'into', 'nato', 'and', 'eventually', 'the', 'eu'], target=['spojené', 'státy', 'a', 'evropská', 'unie', 'se', 'hlásí', 'k', 'odlišné', 'vizi', 'demokratické', 'transformaci', 'a', 'integraci', 'celého', 'balkánu', 'do', 'nato', 'a', 'nakonec', 'do', 'eu']),\n  SentencePair(source=['but', 'they', 'have', 'been', 'reluctant', 'to', 'impose', 'conditions', 'on', 'serbia', 'for', 'fear', 'of', 'bringing', 'even', 'more', 'radical', 'nationalists', 'to', 'power'], target=['zdráhají', 'se', 'ale', 'uvalit', 'na', 'srbsko', 'nějaké', 'podmínky', 'neboť', 'mají', 'strach', 'že', 'by', 'přivedly', 'k', 'moci', 'ještě', 'radikálnější', 'nacionalisty']),\n  SentencePair(source=['in', 'kosovo', 'now', 'that', 'a', 'last', 'ditch', 'round', 'of', 'negotiations', 'has', 'concluded', 'with', 'a', 'report', 'to', 'the', 'un', 'secretary', 'general', 'the', 'us', 'and', 'the', 'eu', 'should', 'agree', 'to', 'recognize', 'kosovo', 'independence', 'provided', 'the', 'kosovars', 'agree', 'to', 'implement', 'the', 'plan', 'submitted', 'by', 'finnish', 'mediator', 'marti', 'ahtisaari'], target=['co', 'se', 'týče', 'kosova', 'usa', 'a', 'eu', 'by', 'se', 'teď', 'když', 'poslední', 'zoufalé', 'kolo', 'vyjednávání', 'skončilo', 'zprávou', 'pro', 'generálního', 'tajemníka', 'osn', 'měly', 'dohodnout', 'na', 'uznání', 'kosovské', 'nezávislosti', 'za', 'předpokladu', 'že', 'kosované', 'budou', 'souhlasit', 's', 'uskutečněním', 'plánu', 'předloženého', 'finským', 'zprostředkovatelem', 'martim', 'ahtisaarim']),\n  SentencePair(source=['the', 'ahtisaari', 'plan', 'provides', 'ample', 'protection', 'for', 'serbs', 'and', 'an', 'international', 'presence', 'in', 'kosovo', 'which', 'the', 'us', 'and', 'the', 'eu', 'will', 'need', 'to', 'deploy', 'even', 'without', 'a', 'new', 'security', 'council', 'resolution', 'to', 'ensure', 'implementation'], target=['ahtisaariho', 'plán', 'zajišťuje', 'dostatek', 'ochrany', 'pro', 'srby', 'a', 'mezinárodní', 'přítomnost', 'v', 'kosovu', 'již', 'budou', 'usa', 'a', 'eu', 'muset', 'zajistit', 'i', 'bez', 'nové', 'rezoluce', 'rady', 'bezpečnosti', 'aby', 'byla', 'zabezpečena', 'realizace']),\n  SentencePair(source=['ironically', 'serbia', 'resistance', 'to', 'the', 'ahtisaari', 'plan', 'undermines', 'protection', 'for', 'kosovo', 'serbs', 'and', 'increases', 'the', 'risk', 'that', 'they', 'will', 'be', 'mistreated'], target=['je', 'ironické', 'že', 'odpor', 'srbska', 'vůči', 'ahtisaariho', 'plánu', 'podrývá', 'ochranu', 'kosovských', 'srbů', 'a', 'zvyšuje', 'riziko', 'že', 's', 'nimi', 'bude', 'zle', 'nakládáno']),\n  SentencePair(source=['it', 'worked', 'against', 'libya', 'leading', 'muammar', 'khadafi', 'in', 'the', 'late', '1990', 'to', 'stop', 'sponsoring', 'terrorism', 'turn', 'over', 'the', 'lockerbie', 'bombers', 'for', 'trial', 'and', 'pay', 'compensation', 'to', 'british', 'and', 'french', 'victims', 'of', 'libyan', 'sponsored', 'terrorism'], target=['osvědčilo', 'se', 'vůči', 'libyi', 'když', 'na', 'konci', '90', 'let', 'přimělo', 'muammara', 'kaddáfího', 'aby', 'přestal', 'finančně', 'podporovat', 'terorismus', 'vydal', 'atentátníky', 'z', 'aféry', 'lockerbie', 'k', 'soudu', 'a', 'vyplatil', 'odškodné', 'britským', 'a', 'francouzským', 'obětem', 'libyí', 'sponzorovaného', 'terorismu']),\n  SentencePair(source=['claims', 'that', 'he', 'abandoned', 'his', 'nuclear', 'program', 'in', 'response', 'to', 'the', 'us', 'led', 'invasion', 'of', 'iraq', 'have', 'been', 'refuted', 'by', 'flynt', 'leverett', 'director', 'for', 'middle', 'eastern', 'affairs', 'at', 'the', 'us', 'national', 'security', 'council', 'from', '2002', 'to', '2003'], target=['tvrzení', 'že', 'od', 'svého', 'jaderného', 'programu', 'ustoupil', 'v', 'reakci', 'na', 'invazi', 'do', 'iráku', 'pod', 'vedením', 'usa', 'vyvrátil', 'flynt', 'leverett', 'ředitel', 'pro', 'otázky', 'středního', 'východu', 'národní', 'bezpečnostní', 'rady', 'usa', 'v', 'letech', '2002', 'až', '2003']),\n  SentencePair(source=['according', 'to', 'leverett', 'khadafi', 'decision', 'predated', 'the', 'invasion', 'and', 'was', 'a', 'response', 'to', 'an', 'explicit', 'quid', 'pro', 'quo', 'to', 'end', 'international', 'sanctions', 'against', 'libya'], target=['podle', 'leveretta', 'padlo', 'kaddáfího', 'rozhodnutí', 'ještě', 'před', 'invazí', 'a', 'bylo', 'odpovědí', 'na', 'explicitní', 'podmínečnou', 'nabídku', 'ukončení', 'mezinárodních', 'sankcí', 'vůči', 'libyi'])],\n [LabeledAlignment(sure=[('1', '3'), ('11', '23'), ('12', '11'), ('13', '12'), ('14', '13'), ('15', '14'), ('17', '17'), ('19', '15'), ('20', '16'), ('21', '18'), ('25', '19'), ('27', '21'), ('28', '24'), ('4', '4'), ('5', '6'), ('7', '7'), ('8', '8'), ('9', '9')], possible=[('1', '1'), ('10', '10'), ('10', '5'), ('16', '16'), ('18', '17'), ('24', '19'), ('26', '21'), ('27', '20'), ('3', '4'), ('5', '7'), ('6', '6'), ('6', '7'), ('7', '6')]),\n  LabeledAlignment(sure=[('13', '11'), ('15', '12'), ('17', '13'), ('18', '14'), ('18', '15'), ('19', '16'), ('2', '2'), ('21', '17'), ('23', '18'), ('26', '20'), ('27', '21'), ('28', '22'), ('29', '23'), ('3', '3'), ('30', '26'), ('31', '27'), ('32', '28'), ('33', '29'), ('35', '34'), ('36', '35'), ('38', '33'), ('4', '4'), ('40', '30'), ('41', '31'), ('42', '36'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '1')], possible=[('1', '1'), ('10', '10'), ('10', '9'), ('11', '10'), ('12', '10'), ('12', '9'), ('16', '15'), ('20', '17'), ('22', '17'), ('24', '18'), ('25', '19'), ('30', '24'), ('30', '25'), ('34', '35'), ('37', '32'), ('37', '33'), ('38', '32'), ('39', '31')]),\n  LabeledAlignment(sure=[('11', '11'), ('13', '12'), ('14', '13'), ('16', '14'), ('18', '15'), ('19', '17'), ('2', '1'), ('20', '17'), ('21', '19'), ('22', '20'), ('23', '21'), ('25', '5'), ('26', '5'), ('28', '6'), ('29', '7'), ('3', '2'), ('30', '22'), ('4', '3'), ('5', '4'), ('7', '8'), ('8', '9'), ('9', '10')], possible=[('1', '1'), ('10', '11'), ('12', '12'), ('15', '14'), ('17', '15'), ('18', '16'), ('24', '21'), ('27', '7'), ('6', '8')]),\n  LabeledAlignment(sure=[('1', '2'), ('10', '9'), ('11', '10'), ('12', '11'), ('13', '12'), ('2', '1'), ('3', '3'), ('4', '5'), ('6', '6'), ('7', '7'), ('9', '8')], possible=[('4', '4'), ('8', '9')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '5'), ('13', '7'), ('15', '6'), ('18', '9'), ('19', '8'), ('2', '1'), ('21', '10'), ('22', '11'), ('24', '13'), ('24', '14'), ('25', '15'), ('26', '12'), ('27', '16'), ('4', '2'), ('6', '3'), ('7', '4'), ('8', '5'), ('9', '5')], possible=[('11', '7'), ('12', '7'), ('14', '6'), ('16', '10'), ('17', '10'), ('20', '8'), ('23', '12'), ('3', '1'), ('5', '2')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '10'), ('12', '11'), ('14', '13'), ('14', '14'), ('16', '12'), ('17', '15'), ('19', '16'), ('20', '17'), ('21', '19'), ('23', '20'), ('24', '21'), ('25', '22'), ('26', '23'), ('27', '29'), ('28', '30'), ('29', '25'), ('30', '28'), ('31', '26'), ('33', '31'), ('6', '7'), ('9', '9')], possible=[('11', '11'), ('13', '12'), ('13', '14'), ('15', '13'), ('15', '14'), ('18', '17'), ('2', '1'), ('2', '2'), ('21', '18'), ('22', '20'), ('26', '24'), ('3', '1'), ('31', '27'), ('32', '26'), ('32', '27'), ('5', '6'), ('5', '7'), ('7', '8'), ('8', '9')]),\n  LabeledAlignment(sure=[('1', '2'), ('10', '5'), ('13', '7'), ('14', '8'), ('15', '9'), ('17', '18'), ('18', '19'), ('19', '20'), ('21', '11'), ('24', '12'), ('25', '13'), ('26', '14'), ('27', '15'), ('28', '16'), ('29', '17'), ('33', '22'), ('34', '27'), ('35', '29'), ('36', '24'), ('37', '25'), ('39', '30'), ('40', '31'), ('41', '32'), ('41', '35'), ('42', '33'), ('43', '34'), ('44', '36'), ('45', '37'), ('46', '38'), ('47', '39'), ('9', '4')], possible=[('11', '9'), ('12', '9'), ('16', '10'), ('20', '21'), ('22', '13'), ('23', '13'), ('3', '1'), ('37', '23'), ('38', '25'), ('4', '1'), ('5', '1'), ('7', '6'), ('8', '6')]),\n  LabeledAlignment(sure=[('1', '2'), ('10', '8'), ('11', '16'), ('12', '15'), ('13', '9'), ('14', '10'), ('15', '11'), ('16', '12'), ('17', '13'), ('18', '17'), ('3', '3'), ('5', '1'), ('6', '6'), ('7', '7')], possible=[('2', '3'), ('7', '4'), ('8', '9'), ('9', '9')]),\n  LabeledAlignment(sure=[('1', '3'), ('11', '9'), ('12', '13'), ('13', '12'), ('14', '14'), ('15', '15'), ('16', '16'), ('17', '17'), ('18', '18'), ('19', '19'), ('20', '20'), ('21', '21'), ('22', '22'), ('3', '1'), ('3', '2'), ('4', '6'), ('5', '5'), ('6', '7'), ('7', '8'), ('8', '10'), ('9', '11')], possible=[('10', '12'), ('2', '1'), ('5', '4'), ('5', '7')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '9'), ('11', '10'), ('12', '11'), ('13', '12'), ('14', '13'), ('15', '14'), ('17', '5'), ('18', '15'), ('2', '2'), ('3', '3'), ('4', '4'), ('7', '6'), ('8', '7'), ('9', '8')], possible=[('16', '5'), ('5', '6'), ('6', '6')]),\n  LabeledAlignment(sure=[('1', '12'), ('10', '8'), ('11', '1'), ('12', '3'), ('13', '4'), ('14', '5'), ('15', '6'), ('16', '15'), ('2', '14'), ('5', '9'), ('7', '10'), ('8', '7')], possible=[('12', '2'), ('4', '14'), ('6', '9'), ('9', '8')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '7'), ('12', '8'), ('13', '9'), ('14', '10'), ('15', '11'), ('16', '12'), ('17', '13'), ('18', '14'), ('19', '15'), ('22', '20'), ('23', '21'), ('25', '22'), ('26', '23'), ('27', '24'), ('28', '25'), ('29', '26'), ('3', '2'), ('30', '27'), ('31', '28'), ('33', '17'), ('34', '17'), ('35', '29'), ('4', '3'), ('6', '4'), ('8', '5'), ('9', '6')], possible=[('11', '9'), ('20', '16'), ('24', '22'), ('32', '17'), ('33', '19'), ('5', '4'), ('7', '5')]),\n  LabeledAlignment(sure=[('10', '9'), ('11', '10'), ('12', '11'), ('13', '12'), ('14', '13'), ('16', '14'), ('18', '16'), ('19', '17'), ('20', '18'), ('21', '19'), ('22', '20'), ('23', '22'), ('24', '23'), ('26', '24'), ('27', '25'), ('28', '26'), ('3', '4'), ('5', '6'), ('8', '7'), ('9', '8')], possible=[('1', '1'), ('10', '5'), ('15', '14'), ('17', '15'), ('2', '1'), ('22', '21'), ('25', '25'), ('3', '3'), ('4', '2'), ('6', '6'), ('7', '9')]),\n  LabeledAlignment(sure=[('10', '9'), ('12', '8'), ('13', '8'), ('14', '10'), ('15', '11'), ('16', '13'), ('17', '12'), ('18', '14'), ('19', '20'), ('20', '15'), ('21', '17'), ('22', '16'), ('24', '18'), ('25', '19'), ('28', '23'), ('3', '1'), ('30', '24'), ('31', '26'), ('33', '27'), ('34', '29'), ('35', '30'), ('36', '30'), ('37', '30'), ('38', '31'), ('5', '3'), ('6', '4'), ('7', '5'), ('8', '6'), ('9', '7')], possible=[('11', '9'), ('23', '19'), ('26', '21'), ('27', '22'), ('29', '24'), ('31', '25'), ('32', '27'), ('33', '28'), ('4', '2')]),\n  LabeledAlignment(sure=[('1', '10'), ('10', '8'), ('11', '11'), ('11', '9'), ('13', '12'), ('14', '14'), ('16', '15'), ('19', '18'), ('2', '1'), ('20', '19'), ('21', '20'), ('22', '16'), ('23', '21'), ('24', '22'), ('25', '23'), ('26', '23'), ('27', '23'), ('28', '24'), ('3', '2'), ('4', '3'), ('5', '7'), ('6', '4'), ('7', '6'), ('9', '5')], possible=[('12', '11'), ('14', '13'), ('15', '15'), ('17', '16'), ('18', '16'), ('8', '5')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '5'), ('12', '8'), ('13', '9'), ('14', '10'), ('15', '11'), ('16', '12'), ('18', '13'), ('19', '14'), ('2', '2'), ('21', '15'), ('22', '15'), ('23', '15'), ('24', '16'), ('25', '18'), ('26', '17'), ('27', '19'), ('28', '20'), ('29', '21'), ('3', '3'), ('30', '22'), ('31', '23'), ('32', '24'), ('33', '25'), ('34', '26'), ('35', '27'), ('37', '29'), ('38', '30'), ('39', '31'), ('4', '3'), ('40', '32'), ('41', '33'), ('43', '34'), ('44', '35'), ('46', '36'), ('48', '37'), ('49', '39'), ('5', '3'), ('50', '40'), ('6', '4')], possible=[('11', '8'), ('17', '13'), ('20', '16'), ('36', '28'), ('36', '30'), ('42', '35'), ('45', '36'), ('47', '39'), ('7', '5'), ('8', '5'), ('9', '5')]),\n  LabeledAlignment(sure=[('10', '10'), ('12', '11'), ('14', '12'), ('15', '13'), ('16', '15'), ('17', '16'), ('2', '1'), ('21', '17'), ('22', '17'), ('23', '17'), ('24', '18'), ('25', '20'), ('25', '21'), ('28', '23'), ('3', '3'), ('30', '24'), ('31', '25'), ('32', '26'), ('33', '27'), ('34', '28'), ('35', '29'), ('36', '30'), ('37', '31'), ('5', '6'), ('6', '7'), ('8', '8'), ('9', '9')], possible=[('1', '1'), ('11', '10'), ('11', '11'), ('13', '13'), ('16', '14'), ('19', '19'), ('20', '19'), ('25', '22'), ('26', '22'), ('27', '27'), ('29', '24'), ('3', '2'), ('7', '8')]),\n  LabeledAlignment(sure=[('1', '11'), ('10', '5'), ('11', '5'), ('12', '5'), ('13', '6'), ('14', '7'), ('17', '16'), ('18', '17'), ('19', '18'), ('20', '19'), ('21', '20'), ('22', '21'), ('23', '22'), ('24', '23'), ('25', '24'), ('26', '25'), ('27', '26'), ('3', '9'), ('4', '10'), ('4', '8'), ('6', '1'), ('7', '3'), ('8', '2'), ('9', '4')], possible=[('16', '16'), ('2', '10'), ('5', '1')]),\n  LabeledAlignment(sure=[('1', '1'), ('11', '16'), ('12', '17'), ('14', '15'), ('16', '18'), ('18', '14'), ('19', '14'), ('2', '1'), ('20', '19'), ('3', '2'), ('4', '4'), ('5', '9'), ('6', '5'), ('6', '7'), ('7', '8'), ('8', '8')], possible=[('13', '17'), ('15', '18'), ('17', '18'), ('18', '12'), ('4', '3'), ('7', '6'), ('8', '6'), ('9', '10')]),\n  LabeledAlignment(sure=[('1', '6'), ('10', '7'), ('10', '8'), ('10', '9'), ('12', '11'), ('14', '13'), ('15', '14'), ('16', '12'), ('17', '15'), ('2', '1'), ('3', '2'), ('4', '3'), ('5', '4'), ('7', '5'), ('8', '10')], possible=[('11', '9'), ('13', '12'), ('6', '4'), ('9', '10')]),\n  LabeledAlignment(sure=[('11', '3'), ('13', '4'), ('15', '5'), ('16', '11'), ('2', '7'), ('3', '8'), ('4', '9'), ('5', '6'), ('6', '6'), ('7', '10'), ('9', '1')], possible=[('1', '7'), ('10', '3'), ('11', '2'), ('12', '5'), ('14', '4'), ('8', '1')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '8'), ('11', '9'), ('12', '11'), ('13', '12'), ('14', '13'), ('15', '16'), ('16', '17'), ('17', '14'), ('18', '15'), ('19', '18'), ('3', '3'), ('4', '4'), ('5', '5'), ('5', '6'), ('6', '2')], possible=[('10', '7'), ('12', '10'), ('2', '2'), ('7', '2'), ('8', '7'), ('9', '7'), ('9', '8')]),\n  LabeledAlignment(sure=[('1', '1'), ('11', '11'), ('12', '12'), ('13', '13'), ('14', '15'), ('15', '7'), ('16', '8'), ('17', '9'), ('18', '16'), ('3', '2'), ('4', '3'), ('6', '4'), ('7', '5'), ('9', '10'), ('9', '6')], possible=[('10', '12'), ('2', '1'), ('5', '5'), ('8', '10')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '9'), ('11', '10'), ('12', '11'), ('14', '12'), ('16', '14'), ('17', '15'), ('2', '2'), ('4', '5'), ('6', '3'), ('7', '4'), ('8', '7'), ('9', '8')], possible=[('13', '13'), ('15', '14'), ('5', '4')]),\n  LabeledAlignment(sure=[('1', '8'), ('10', '9'), ('11', '10'), ('12', '11'), ('14', '12'), ('15', '13'), ('16', '14'), ('18', '16'), ('19', '17'), ('20', '20'), ('21', '21'), ('21', '22'), ('22', '23'), ('23', '24'), ('3', '2'), ('4', '3'), ('5', '4'), ('6', '5'), ('7', '6'), ('8', '7'), ('9', '9')], possible=[('2', '8'), ('20', '19')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '7'), ('11', '8'), ('13', '13'), ('16', '15'), ('16', '16'), ('18', '21'), ('19', '21'), ('2', '2'), ('22', '20'), ('23', '19'), ('24', '19'), ('25', '22'), ('3', '3'), ('4', '4'), ('5', '5'), ('7', '10'), ('8', '11')], possible=[('12', '12'), ('14', '14'), ('15', '14'), ('17', '17'), ('17', '18'), ('20', '20'), ('20', '21'), ('21', '20'), ('6', '6'), ('8', '9'), ('9', '6')]),\n  LabeledAlignment(sure=[('1', '1'), ('11', '8'), ('12', '9'), ('13', '10'), ('14', '11'), ('15', '12'), ('15', '13'), ('16', '14'), ('17', '15'), ('18', '16'), ('19', '17'), ('21', '18'), ('22', '19'), ('23', '20'), ('25', '21'), ('26', '22'), ('27', '23'), ('28', '24'), ('5', '4'), ('6', '5'), ('7', '6'), ('9', '7')], possible=[('10', '8'), ('10', '9'), ('2', '2'), ('20', '19'), ('24', '23'), ('3', '3'), ('4', '5'), ('8', '7')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '10'), ('11', '11'), ('2', '2'), ('4', '4'), ('5', '6'), ('6', '7'), ('7', '8'), ('9', '9')], possible=[('3', '3'), ('4', '3'), ('4', '5'), ('8', '9')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '10'), ('11', '11'), ('12', '12'), ('13', '13'), ('15', '14'), ('16', '15'), ('17', '17'), ('18', '18'), ('2', '2'), ('21', '19'), ('22', '20'), ('23', '21'), ('24', '22'), ('25', '23'), ('26', '24'), ('27', '25'), ('28', '26'), ('3', '3'), ('30', '27'), ('31', '28'), ('32', '29'), ('33', '29'), ('34', '32'), ('35', '30'), ('35', '31'), ('36', '33'), ('37', '34'), ('39', '35'), ('4', '4'), ('40', '36'), ('41', '37'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '8'), ('9', '9')], possible=[('14', '18'), ('16', '16'), ('17', '16'), ('19', '22'), ('20', '22'), ('38', '36')]),\n  LabeledAlignment(sure=[('1', '1'), ('11', '7'), ('12', '8'), ('13', '9'), ('2', '2'), ('3', '3'), ('6', '4'), ('8', '5'), ('9', '6')], possible=[('10', '7'), ('4', '3'), ('5', '4'), ('7', '6')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '9'), ('11', '10'), ('12', '11'), ('13', '12'), ('14', '13'), ('15', '14'), ('16', '14'), ('17', '14'), ('18', '15'), ('2', '3'), ('21', '16'), ('22', '17'), ('23', '18'), ('24', '19'), ('25', '20'), ('3', '4'), ('4', '5'), ('5', '6'), ('6', '6'), ('7', '7'), ('9', '8')], possible=[('19', '16'), ('2', '2'), ('20', '16'), ('8', '9')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '3'), ('14', '4'), ('15', '5'), ('16', '6'), ('17', '7'), ('18', '8'), ('19', '9'), ('2', '1'), ('20', '9'), ('21', '10'), ('22', '11'), ('23', '12'), ('25', '13'), ('26', '14'), ('27', '15'), ('28', '21'), ('3', '1'), ('4', '2'), ('6', '17'), ('7', '19'), ('9', '20')], possible=[('13', '5'), ('24', '15'), ('5', '17')]),\n  LabeledAlignment(sure=[('10', '9'), ('11', '12'), ('2', '1'), ('3', '2'), ('4', '4'), ('5', '5'), ('7', '3'), ('8', '6')], possible=[('1', '7'), ('6', '5'), ('9', '9')]),\n  LabeledAlignment(sure=[('1', '6'), ('10', '17'), ('12', '15'), ('13', '18'), ('14', '19'), ('15', '16'), ('16', '16'), ('17', '16'), ('18', '20'), ('2', '7'), ('5', '9'), ('7', '11'), ('8', '12')], possible=[('10', '14'), ('11', '15'), ('3', '7'), ('4', '12'), ('6', '10'), ('8', '13'), ('8', '8'), ('9', '14'), ('9', '17')]),\n  LabeledAlignment(sure=[('1', '2'), ('10', '8'), ('11', '9'), ('12', '10'), ('13', '11'), ('14', '14'), ('15', '15'), ('16', '16'), ('2', '1'), ('4', '3'), ('7', '4')], possible=[('3', '3'), ('5', '4'), ('6', '4'), ('8', '6'), ('9', '5')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '9'), ('11', '7'), ('12', '7'), ('13', '10'), ('14', '11'), ('15', '12'), ('16', '13'), ('18', '14'), ('2', '2'), ('20', '15'), ('21', '16'), ('3', '3'), ('4', '4'), ('7', '7'), ('8', '8')], possible=[('17', '14'), ('17', '15'), ('19', '14'), ('5', '5'), ('5', '7'), ('6', '7'), ('7', '5'), ('9', '9')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '10'), ('13', '11'), ('16', '12'), ('17', '13'), ('18', '14'), ('2', '1'), ('20', '15'), ('22', '4'), ('23', '5'), ('24', '6'), ('26', '16'), ('3', '1'), ('5', '7'), ('7', '8'), ('8', '9')], possible=[('11', '11'), ('12', '11'), ('14', '14'), ('15', '14'), ('19', '15'), ('21', '4'), ('4', '1'), ('6', '9'), ('9', '10')]),\n  LabeledAlignment(sure=[('10', '7'), ('11', '8'), ('12', '9'), ('13', '10'), ('13', '11'), ('15', '13'), ('17', '12'), ('19', '15'), ('2', '3'), ('20', '16'), ('21', '17'), ('23', '19'), ('24', '18'), ('25', '20'), ('4', '1'), ('5', '2'), ('7', '4'), ('7', '5'), ('9', '6')], possible=[('14', '13'), ('16', '12'), ('18', '15'), ('22', '18'), ('3', '3'), ('6', '5'), ('8', '6')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '13'), ('11', '14'), ('12', '5'), ('13', '6'), ('14', '7'), ('16', '15'), ('3', '8'), ('4', '9'), ('6', '10'), ('8', '12'), ('9', '11')], possible=[('12', '2'), ('2', '1'), ('5', '11'), ('7', '10')]),\n  LabeledAlignment(sure=[('1', '1'), ('11', '6'), ('12', '7'), ('14', '5'), ('15', '9'), ('16', '10'), ('17', '8'), ('2', '2'), ('20', '18'), ('21', '19'), ('24', '23'), ('25', '27'), ('26', '24'), ('28', '25'), ('29', '26'), ('3', '3'), ('30', '28'), ('31', '29'), ('32', '30'), ('33', '31'), ('35', '33'), ('36', '34'), ('38', '32'), ('39', '35'), ('4', '11'), ('5', '12'), ('6', '13'), ('7', '14'), ('8', '16'), ('9', '15')], possible=[('10', '4'), ('13', '5'), ('18', '17'), ('19', '18'), ('24', '22'), ('24', '27'), ('27', '26'), ('34', '32'), ('37', '34')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '7'), ('11', '6'), ('12', '8'), ('13', '9'), ('14', '11'), ('16', '12'), ('17', '13'), ('18', '14'), ('19', '15'), ('2', '2'), ('20', '16'), ('5', '4'), ('8', '5')], possible=[('3', '3'), ('4', '3'), ('6', '3'), ('7', '3'), ('9', '6')]),\n  LabeledAlignment(sure=[('1', '5'), ('10', '4'), ('11', '3'), ('12', '1'), ('14', '2'), ('15', '13'), ('2', '7'), ('5', '8'), ('6', '9'), ('7', '10'), ('8', '11'), ('9', '12')], possible=[('13', '1'), ('2', '6'), ('4', '8'), ('5', '6')]),\n  LabeledAlignment(sure=[('10', '8'), ('12', '9'), ('13', '10'), ('14', '11'), ('15', '12'), ('16', '13'), ('17', '14'), ('18', '15'), ('2', '1'), ('20', '16'), ('23', '17'), ('24', '18'), ('25', '19'), ('26', '20'), ('27', '21'), ('29', '23'), ('3', '2'), ('30', '24'), ('4', '3'), ('6', '4'), ('7', '5'), ('9', '6'), ('9', '7')], possible=[('1', '2'), ('11', '10'), ('19', '17'), ('21', '16'), ('21', '17'), ('22', '16'), ('22', '17'), ('24', '22'), ('28', '23'), ('5', '5'), ('8', '7')]),\n  LabeledAlignment(sure=[('1', '3'), ('10', '6'), ('11', '9'), ('13', '12'), ('15', '16'), ('16', '19'), ('17', '20'), ('18', '20'), ('19', '21'), ('20', '17'), ('21', '18'), ('22', '22'), ('5', '1'), ('5', '2'), ('7', '4'), ('8', '8'), ('9', '5')], possible=[('12', '10'), ('14', '13'), ('14', '14'), ('15', '15'), ('2', '1'), ('2', '2'), ('3', '1'), ('4', '1'), ('6', '4')]),\n  LabeledAlignment(sure=[('10', '17'), ('12', '18'), ('14', '19'), ('17', '20'), ('18', '21'), ('2', '4'), ('20', '24'), ('21', '23'), ('22', '22'), ('25', '6'), ('26', '7'), ('28', '8'), ('29', '26'), ('30', '27'), ('32', '29'), ('33', '30'), ('35', '31'), ('37', '33'), ('37', '34'), ('39', '37'), ('4', '11'), ('40', '39'), ('42', '41'), ('44', '42'), ('45', '43'), ('47', '44'), ('48', '45'), ('49', '46'), ('5', '13'), ('50', '47'), ('51', '48'), ('7', '14'), ('9', '16')], possible=[('11', '18'), ('13', '19'), ('15', '20'), ('16', '20'), ('19', '23'), ('23', '25'), ('24', '6'), ('27', '8'), ('29', '9'), ('3', '5'), ('30', '10'), ('31', '28'), ('34', '30'), ('36', '32'), ('37', '35'), ('37', '36'), ('38', '37'), ('40', '38'), ('41', '40'), ('41', '41'), ('43', '42'), ('46', '45'), ('46', '47'), ('5', '12'), ('6', '17'), ('8', '15'), ('8', '16'), ('9', '15')]),\n  LabeledAlignment(sure=[('11', '9'), ('12', '10'), ('13', '11'), ('14', '12'), ('15', '13'), ('16', '14'), ('18', '16'), ('19', '17'), ('2', '1'), ('21', '18'), ('23', '19'), ('25', '20'), ('26', '21'), ('27', '22'), ('29', '23'), ('3', '2'), ('30', '26'), ('31', '25'), ('32', '24'), ('33', '27'), ('34', '28'), ('35', '30'), ('36', '31'), ('37', '32'), ('4', '3'), ('5', '4'), ('6', '5'), ('7', '6'), ('8', '7'), ('9', '8')], possible=[('1', '2'), ('10', '10'), ('17', '16'), ('20', '18'), ('22', '15'), ('22', '19'), ('23', '15'), ('24', '19'), ('24', '20'), ('28', '24'), ('35', '29')]),\n  LabeledAlignment(sure=[('1', '2'), ('10', '10'), ('11', '11'), ('13', '12'), ('15', '13'), ('16', '14'), ('17', '15'), ('19', '16'), ('20', '18'), ('24', '22'), ('24', '23'), ('25', '24'), ('3', '6'), ('5', '5'), ('6', '7'), ('8', '8'), ('9', '9')], possible=[('12', '13'), ('14', '12'), ('18', '16'), ('2', '3'), ('20', '17'), ('21', '20'), ('21', '21'), ('21', '23'), ('22', '21'), ('22', '23'), ('23', '21'), ('23', '23'), ('24', '21'), ('4', '6'), ('7', '9')]),\n  LabeledAlignment(sure=[('11', '8'), ('15', '17'), ('16', '18'), ('16', '19'), ('17', '20'), ('19', '22'), ('20', '22'), ('22', '26'), ('23', '23'), ('24', '27'), ('25', '28'), ('27', '29'), ('28', '30'), ('29', '31'), ('3', '3'), ('31', '32'), ('32', '33'), ('33', '34'), ('34', '35'), ('36', '36'), ('38', '37'), ('39', '38'), ('4', '4'), ('40', '39'), ('6', '12'), ('7', '13'), ('8', '14'), ('9', '7')], possible=[('1', '1'), ('1', '39'), ('10', '8'), ('12', '10'), ('12', '11'), ('12', '9'), ('13', '10'), ('13', '11'), ('13', '9'), ('14', '15'), ('14', '16'), ('14', '17'), ('18', '21'), ('2', '1'), ('2', '2'), ('21', '23'), ('26', '29'), ('30', '32'), ('30', '35'), ('35', '38'), ('37', '36'), ('5', '5')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '11'), ('12', '17'), ('14', '16'), ('15', '12'), ('17', '14'), ('2', '3'), ('20', '19'), ('22', '20'), ('23', '21'), ('24', '22'), ('25', '23'), ('26', '24'), ('27', '26'), ('28', '27'), ('29', '25'), ('32', '31'), ('33', '28'), ('34', '29'), ('35', '30'), ('37', '34'), ('39', '36'), ('4', '8'), ('40', '37'), ('5', '5'), ('6', '6'), ('7', '7'), ('8', '9'), ('9', '10')], possible=[('11', '12'), ('13', '16'), ('14', '15'), ('16', '13'), ('16', '14'), ('18', '19'), ('19', '19'), ('2', '2'), ('20', '18'), ('21', '21'), ('3', '8'), ('30', '30'), ('31', '30'), ('31', '31'), ('38', '35'), ('4', '4')]),\n  LabeledAlignment(sure=[('1', '1'), ('10', '8'), ('11', '9'), ('12', '10'), ('14', '11'), ('15', '12'), ('17', '13'), ('18', '15'), ('19', '15'), ('2', '1'), ('20', '15'), ('21', '15'), ('22', '15'), ('24', '16'), ('25', '17'), ('26', '18'), ('27', '19'), ('28', '20'), ('29', '21'), ('3', '2'), ('5', '4'), ('7', '5')], possible=[('13', '11'), ('16', '15'), ('18', '14'), ('19', '14'), ('20', '14'), ('21', '14'), ('23', '16'), ('4', '2'), ('6', '4'), ('8', '3'), ('8', '7'), ('9', '8')])])"
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import extract_sentences\n",
    "\n",
    "all_sentences = []\n",
    "all_targets = []\n",
    "# (´◕▽◕)⊃━☆\n",
    "extract_sentences('data/merged_data/named_entities/project_syndicate_ne02.wa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание -1. (0.5 балла)** Реализуйте функции `get_token_to_index` и `tokenize_sents` из модуля `preprocessing.py`, постройте словари token->index для обоих языков и постройте список из `TokenizedSentencePair` по выборке. Реализации функций также отправьте в Яндекс.Контест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import get_token_to_index, tokenize_sents\n",
    "\n",
    "t_idx_src, t_idx_tgt = get_token_to_index(all_sentences)\n",
    "tokenized_sentences = tokenize_sents(all_sentences, t_idx_src, t_idx_tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В качестве бейзлайна для этой задачи мы возьмём способ выравнивания слов по коэффициенту Дайса: слово в исходном языке является переводом слова на целевом языке, если они часто встречаются в одних и тех же предложениях и редко встречаются по отдельности. \n",
    "\n",
    "Математически это записывается по аналогии с мерой Жаккара: пусть $c(x,y)$ — число параллельных предложений, в которых есть и $x$ (на исходном языке), и $y$ (на целевом языке), а $c(x)$ и $c(y)$ — суммарное количество предложений, в которых встречается слово $x$ и $y$ соответственно. Тогда $\\textrm{Dice}(x,y)=\\frac{2 \\cdot c(x,y)}{c(x) + c(y)}$ — характеристика «похожести» слов $x$ и $y$. Она равна 1, если слова встречаются только в контексте друг друга (не бывает предложений только со словом $x$ без $y$ в переводе и наоборот), равна 0, если слова никогда не встречаются в параллельных предложениях и находится между пороговыми значениями в остальных случаях.\n",
    "\n",
    "В файле `models.py` описан абстрактный класс `BaseAligner`, наследником которого должны являться все модели в задании, а также приведён пример реализации `DiceAligner` выравнивания слов описанным выше путём. Ниже вы можете увидеть, как применять эту модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import DiceAligner\n",
    "\n",
    "baseline = DiceAligner(len(t_idx_src), len(t_idx_tgt), threshold=0.01)\n",
    "baseline.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Чтобы оценить качество модели выравнивания, пользуясь имеющейся разметкой, существует ряд автоматических метрик. Они подразумевают, что в разметке есть два вида выравниваний — «уверенные» (sure) и «возможные» (possible). Обозначим для конкретного предложения первое множество выравниваний $S$, второе — $P$, а предсказанные выравнивания — $A$; причём, в отличие от разметки в файле, $S\\subseteq P$. Тогда можно предложить три метрики, используя только операции над этими множествами:\n",
    "\n",
    "Precision $=\\frac{|A\\cap P|}{|A|}$. Отражает, какая доля предсказанных нами выравниваний вообще корректна; если мы дадим в качестве ответа все возможные пары слов в предложении, эта метрика сильно просядет.\n",
    "\n",
    "Recall $=\\frac{|A\\cap S|}{|S|}$. Эта метрика показывает, какую долю «уверенных» выравниваний мы обнаружили. Если мы попытаемся сделать слишком консервативную модель, которая выдаёт 0 или 1 предсказание на нетривиальных предложениях, полнота получится крайне низкая. \n",
    "\n",
    "Alignment Error Rate (AER) $=1-\\frac{|A\\cap P|+|A\\cap S|}{|A|+|S|}$. Метрика является комбинацией двух предыдущих и отслеживает общее качество работы системы, штрафуя оба описанных выше вида нежелаемого поведения модели. \n",
    "\n",
    "**Задание 0. (0.5 балла)** Реализуйте функции compute_precision, compute_recall, compute_aer из модуля metrics.py. Оцените качество бейзлайнового метода. Обратите внимание, что нужно использовать микро-усреднение во всех функциях: необходимо просуммировать числитель и знаменатель по всем предложениям и только потом делить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from metrics import compute_aer\n",
    "\n",
    "compute_aer(all_targets, baseline.align(tokenized_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь мы можем перейти к базовой вероятностной модели для выравнивания слов. Пусть $S=(s_1,\\ldots,s_n)$ исходное предложение, $T=(t_1,\\ldots,t_m)$ — его перевод. В роли латентных переменных будут выступать выравнивания $A=(a_1,\\ldots,a_m)$ каждого слова в целевом предложении, причём $a_i\\in\\{1,\\ldots,n\\}$ (считаем, что каждое слово в $t$ является переводом какого-то слова из $s$). Параметрами модели является матрица условных вероятностей перевода: каждый её элемент $\\theta(y|x)=p(y|x)$ отражает вероятность того, что переводом слова $x$ с исходного языка на целевой является слово $y$ (нормировка, соответственно, совершается по словарю целевого языка). Правдоподобие латентных переменных и предложения на целевом языке в этой модели записывается так:\n",
    "\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i)p(t_i|a_i,S)=\\prod_{i=1}^m \\frac{1}{n}\\theta(t_i|s_{a_i}).\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 1. (2 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия ($\\mathcal{L}$ в обозначениях лекции и семинара). **Обратите внимание, что на M-шаге нужно найти аналитический максимум по параметрам.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "(∩｀-´)⊃━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 2. (2.5 балла)** Реализуйте все методы класса `WordAligner` в соответствии с полученными вами формулами. Протестируйте вашу реализацию через Яндекс.Контест, а здесь обучите модель и посчитайте её AER на истинной разметке. Чтобы предсказать выравнивание для пары предложений в этой модели, следует выбирать в соответствие для слова в целевом предложении с индексом $i$ позицию, соответствующую максимуму апостериорного распределения $p(a_i|T,S)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import WordAligner\n",
    "\n",
    "word_aligner = WordAligner(len(t_idx_src), len(t_idx_tgt), 20)\n",
    "word_aligner.fit(tokenized_sentences);\n",
    "\n",
    "# ༼つ ಠ益ಠ༽つ ─=≡ΣO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заметим, что таблицу вероятностей перевода можно использовать и саму по себе для построения словарей. Пример работы показан ниже: метод хоть и работает, но мягко говоря, неидально — слишком мало данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx_token_tgt = {index: token for token, index in t_idx_tgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mr']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['Mrs']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['water']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['depended']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[idx_token_tgt[i] for i in word_aligner.translation_probs[t_idx_src['on']].argsort()[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 3. (0.5 балла)** Мы смогли получить матрицу условных вероятностей перевода исходного языка в целевой. Можно ли, пользуясь этой матрицей и ещё какими-то статистиками по параллельному корпусу, получить вероятности перевода целевого языка в исходный? Реализуйте такой метод и приведите ниже пример его работы, показав пару удачных переводов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (>ω<)ノ—==ΞΞ☆*✲ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 4. (0.5 балла)** Визуализируйте полученные выравнивания для нескольких предложений в виде heatmap: по одной из осей располагаются токены исходного текста, по другой — токены его перевода, на пересечении позиций $i$ и $j$ — 0 либо 1 в зависимости от того, является ли в обученной модели $a_i$ равным $j$. Можете ли вы их проинтерпретировать? Постройте аналогичный график, но без дискретизации, а визуализируя напрямую апостериорное распределение. Можете ли вы найти ситуации, в которых модель не уверена, переводом какого слова является слово $i$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (•̀ 3 •́)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Заметим, что при задании модели мы сделали довольно сильное предположение о том, что вероятности выбора слова для выравнивания никак не зависят от позиции слова в целевом предложении. Можно сделать эти вероятности настраиваемыми параметрами, получив прямоугольную матрицу $\\phi_{m,n}(j|i)=p(a_i=j|m,n)$ для каждой пары длин предложений $m,n$: по-прежнему мы получаем распределение над индексами в исходном предложении. Тогда модель приобретает вид\n",
    "$$\n",
    "p(A,T|S)=\\prod_{i=1}^m p(a_i|m,n)p(t_i| a_i, S)=\\prod_{i=1}^m \\phi_{m,n}(a_i|i)\\theta(t_i|s_{a_i}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 5. (1.5 балла)** Выведите шаги EM-алгоритма для этой модели, а также получите выражение для подсчёта нижней оценки правдоподобия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ଘ(๑˃̵ᴗ˂̵)━☆ﾟ.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 6. (2 балла)** Реализуйте все методы класса `WordPositionAligner`, протестируйте их корректность через Яндекс.Контест. Обучите модель, оцените её качество на истинной разметке и сравните его с качеством предыдущей более простой модели. Проиллюстрируйте влияние стартовых параметров на результат, проинициализировав эту модель параметрами модели из задания 2 (важно, чтобы суммарное число эпох обучения в обоих сценариях оставалось тем же)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from models import WordPositionAligner\n",
    "# (≧ ◡ ≦)━★☆.*･｡ﾟ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 7. (1 балл)** В предыдущих пунктах мы никак не заостряли внимание на предобработке текстов, что может негативно влиять на результаты обученной модели. Например, сейчас метод выравнивания учитывает регистр, а слова на чешском языке вдобавок обладают богатой морфологией и большим количеством диакритических знаков. Если сократить количество параметров модели (различных слов), можно ускорить обучение и добиться лучших результатов, потому что статистики по словам будут считаться по большему числу параллельных предложений.\n",
    "\n",
    "Примените к исходным данным [Unicode-нормализацию](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization), приведите их к нижнему регистру и обучите модель выравнивания заново. Сравните качество и скорость обучения с предыдущими результатами и сделайте выводы. Если вы найдете в данных ещё какие-то проблемы, которые можно исправить более грамотной предобработкой, также продемонстрируйте, как их решение влияет на качество.\n",
    "\n",
    "**Важно:** здесь и далее в процессе обработки данных у вас может получаться, что из тестовых данных будут удалены предложения из-за отсутствия слов в словаре. Если такое всё же произошло, для корректности сравнения считайте AER вашей модели на удалённых предложениях равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# (੭•̀ω•́)੭̸*✩⁺˚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Задание 7. (бонус, до 3 баллов)** \n",
    "\n",
    "Улучшите качество получившейся системы настолько, насколько сможете. За каждые 5 процентов, на которые AER на тех же данных получается меньше, чем минимум ошибки всех предыдущих моделей, вы получите по 1 бонусному баллу.\n",
    "\n",
    "Ниже приведены несколько идей, которые могут помочь вам повысить \n",
    "\n",
    "* Модифицировать модель: как вы можете понять, недостатком второго реализованного вами подхода является избыточное число параметров из-за необходимости подерживать отдельную матрицу для каждой различной пары длин предложений в корпусе. В статье https://www.aclweb.org/anthology/N13-1073.pdf приведён способ снижения числа параметров, задающих априорное распределение позиций выравнивания, который позволяет в десять раз быстрее обучать модель и получать лучшее качество.\n",
    "* Агрегация по двум направлениям: в статье https://www.aclweb.org/anthology/J03-1002/ утверждается, что асимметричность выравниваний вредит качеству, потому что из-за выбранной модели одному слову в целевом предложении не может соответствовать два слова в исходном предложении. Для решения этой проблемы (и улучшения метрик, разумеется) авторы предлагают несколько алгоритмов, которые можно попробовать применить в этом задании.\n",
    "* Использовать больше обучающих данных. В корпусе, которым мы пользуемся, только пара тысяч предложений, чего может не хватать для по-настоящему хорошей модели выравнивания. Разумеется, неразмеченных параллельных английско-чешских корпусов гораздо больше, поэтому можно воспользоваться ими. Хорошая точка для старта — данные с соревнования по машинному переводу  [воркшопа WMT](http://www.statmt.org/wmt20/translation-task.html).\n",
    "* В языках часто существуют слова наподобие артиклей или предлогов, которым не соответствует ни одно слово в переводе. Все рассмотренные в рамках задания модели это не учитывают, возможно, добавление возможности перевода в «нулевой» токен улучшит качество модели (при тестировании такие выравнивания имеет смысл выбрасывать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ┐_(ツ)_┌━☆ﾟ.*･｡ﾟ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}