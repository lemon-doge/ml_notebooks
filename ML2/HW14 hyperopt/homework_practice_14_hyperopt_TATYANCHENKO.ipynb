{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "weekly-bumper",
      "metadata": {
        "id": "weekly-bumper"
      },
      "source": [
        "# Машинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Бонусное практическое задание 14. Оптимизация гиперпараметров.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 06.06.2022\n",
        "\n",
        "Мягкий и жесткий дедлайны: 26.06.2022 23:59 MSK\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "### Формат сдачи\n",
        "\n",
        "Задания сдаются через систему anytask. Посылка должна содержать:\n",
        "\n",
        "- Ноутбук `homework-practice-14-Username.ipynb`\n",
        "- Модули `distributions.py` и `optimizers.py`, содержащие написанный вами код\n",
        "\n",
        "Username — ваша фамилия на латинице\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит разработать свой собственный AutoML фреймворк, который будет подбирать оптимальные значения гиперпараметров для определенной модели и обучающих данных. Попутно вы познакомитесь с основными концепциями Байесовской оптимизации и узнаете, как Гауссовские процессы и метод Парзеновского окна применяются на практике. Если вы все сделаете правильно, то на выходе получится фреймворк, не уступающий популярной `optuna`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mature-fluid",
      "metadata": {
        "id": "mature-fluid"
      },
      "source": [
        "## 1. AutoML фреймворк (5 баллов)\n",
        "\n",
        "Наш фреймворк будет работать по аналогии с классом [`OptunaSearchCV`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html#optuna.integration.OptunaSearchCV) из пакета `optuna`, который интегрирован с интерфейсом `sklearn`. Общая схема следующая: сначала мы выбираем модель, для которой будем подбирать гиперпараметры, и задаем распределения на них (решаем, будет ли параметр вещественным или целочисленным; определяем границы; выбираем линейную или логарифмическую шкалу). Далее, на каждой итерации мы выбираем новый набор значений гиперпараметров и оцениваем качество модели на них с помощью кросс-валидации. За ограниченное число итераций находим лучший набор гиперпараметров и обучаем итоговую модель на всех данных. Условимся, что мы хотим **максимизировать** значение метрики (в случае, если мы хотим минимизировать метрику, будем брать ее с минусом). Отличие между различными стратегиями поиска заключается в том, как именно выбираются новые значения гиперпараметров. Подробнее об этом ниже.\n",
        "\n",
        "Вашу реализацию кода нужно будет протестировать через [ЯндексКонтест](https://contest.yandex.ru/contest/37803/). Помимо стандартных библиотек Python 3.7, в контесте доступны `numpy=1.21.6`, `scipy=1.7.3` и `scikit-learn=1.0.2`, а также их зависимости.\n",
        "\n",
        "**Задание 1.1 (0.5 балла).** Реализуйте распределения гиперпараметров в файле `distributions.py`. Каждый класс должен поддерживать метод `sample`, который возвращает выборку из распределения. Кроме того, для численных распределений нам понадобится метод `scale`, который переводит выборку в промежуток $[0, 1]$ (с линейной шкалой) (за подробностями обращайтесь к док-строкам в базовых классах). Чуть позже станет понятнее, как нам пригодится эта функция. Задача в контесте: [ссылка](https://contest.yandex.ru/contest/37803/problems/A/).\n",
        "\n",
        "**Задание 1.2 (1 балл).** Реализуйте методы `sample_params`, `cross_validate`, `fit`, `predict` и `predict_proba` класса `BaseOptimizer` в файле `optimizers.py`. Обратите внимание, что разбиение на фолды должно быть одинаковым для каждой итерации оптимизации (чтобы оценивать наборы гиперпараметров честно). Кроме того, не забывайте о воспроизводимости экспериментов: запуски всех алгоритмов, содержащих случайность, должны контролироваться с помощью `random_seed`. Также сохраняйте историю параметров и метрики в поля `self.params_history` и `self.scores_history`.\n",
        "\n",
        "**Задание 1.3 (0.5 балла).** Реализуйте простейшую возможную стратегию &mdash; стратегию случайного поиска в классе `RandomSearchOptimizer` из файла `optimizers.py`. На каждой новой итерации алгоритма мы генерируем новый случайный набор гиперпараметров, не производя никакого дополнительного отбора. Задача в контесте: [ссылка](https://contest.yandex.ru/contest/37803/problems/B/)\n",
        "\n",
        "### Байесовская  оптимизация\n",
        "\n",
        "http://krasserm.github.io/2018/03/21/bayesian-optimization/\n",
        "\n",
        "Далее мы перейдем к более продвинутым методам поиска гиперпараметров. Одним из наиболее распространенных подходов к этой задаче является **Байейсовская оптимизация**. Ее суть состоит в следующем: на каждой итерации мы будем аппроксимировать распределение $p(y|x)$, где $y$ &mdash; это значение метрики, а $x$ &mdash; значение набора гиперпараметров. Допустим, что $y^*$ &mdash; это наилучшее (наибольшее) текущее значение метрики. Чтобы выбрать новое значение гиперпараметров, для которого мы будем учить модель, нам понадобится величина под названием **Expected Impovement (EI)**. Она определяется следующим образом:\n",
        "\n",
        "$$\n",
        "\\text{EI}_{y^*}(x) = \\mathbb{E}_{y \\sim p(y|x)} \\Big[\\max(0, y - y^*)\\Big] = \\int \\max(0, y - y^*) p(y|x) dy\n",
        "$$\n",
        "\n",
        "Соответственно, чем выше значение EI, тем большего увеличения $y^*$ мы ожидаем, обучив модель с гиперпараметрами $x$. Таким образом, на каждой итерации оптимизации мы будем семлировать несколько кандидатов $x_i, i=1, \\dots, N$ из исходного распределения гиперпараметров и выбирать из них наилучшего путем максимизации EI: $x_{\\text{new}} = \\arg\\max_{x_i} \\big\\{\\text{EI}_{y^*} (x_i)\\big\\}$. Нам осталось обсудить, как именно аппроксимировать распределение $p(y|x)$.\n",
        "\n",
        "### Гауссовские процессы\n",
        "\n",
        "http://krasserm.github.io/2018/03/19/gaussian-processes/\n",
        "\n",
        "[Гауссовские процессы](https://en.wikipedia.org/wiki/Gaussian_process) (ГП) &mdash; одна из популярных опций для задания распределения $p(y|x)$. Если не вдаваться в глубокую теорию, то можно воспринимать ГП как случайные функции. ГП задаются двумя параметрами: функцией среднего $\\mu(x)$ и ковариационной функцией $K(x, x')$. Процесс называется гауссовским, поскольку в каждой отдельно взятой точке $x$ мы имеем нормальное распределение: $y(x) \\sim \\mathcal{N}\\big(\\mu(x), K(x, x)\\big)$. А условие $\\text{Cov}\\big(y(x), y(x')\\big) = K(x, x')$ объясняет название ковариационной функции. Как правило, для практических применений достаточно так называемых стационарных ГП, которые отличают константная функция среднего $\\mu(x)=\\text{const}$ (чаще всего даже $\\mu(x)=0$) и ковариационная функция, зависящая только от расстояния между точками: $K(x, x') = K\\big(\\|x-x'\\|\\big)$. Часто под переменной $x$ понимают время (отсюда название \"процесс\"), но мы будет рассматривать в качестве $x$ наше пространство гиперпараметров.\n",
        "\n",
        "На первый взгляд может показаться, что ГП мало чем могут быть полезны: ведь в каждой точке $x$ у нас свое собственное случайное значение $y$. Но оказывается, что если ковариационная функция непрерывна в нуле, то (почти все) реализации ГП (то есть интересующие нас случайные значения $y(x)$) непрерывны. Таким образом, каждая реализация ГП соответствует некоторой непрерывной функции, а значит, ГП можно использовать для регрессии.\n",
        "\n",
        "Если задана обучающая выборка $\\{(x_i, y_i)\\}_{i=1}^{\\ell}$, то мы можем посчитать распределение $p(y|x) = \\mathcal{N}\\big(y\\big|\\mu(x), \\sigma^2(x)\\big)$ для любой точки $x$ (замечание: здесь уже не будет выполняться $\\mu(x)=0$, так как распределение на $y$ апостериорное, то есть зависит от обучающих данных). При этом, для разных ковариационных функций мы будем получать разные распределения. Обычно в качестве ковариационных функций используют ядра (да-да, те самые из теоремы Мерсера). Нам повезло, что все это уже реализовано в классе [`sklearn.gaussian_process.GaussianProcessRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#sklearn.gaussian_process.GaussianProcessRegressor), и мы можем сконцентрироваться на алгоритмах оптимизации гиперпараметров.\n",
        "\n",
        "Ниже приведен пример регрессии с помощью ГП:\n",
        "![](https://www.researchgate.net/profile/Florent-Leclercq/publication/327613136/figure/fig1/AS:749406701776896@1555683889137/Illustration-of-Gaussian-process-regression-in-one-dimension-for-the-target-test.png)\n",
        "\n",
        "Впрочем, в нашем случае, картинка будет выглядеть скорее так, поскольку $x$ будет многомерным:\n",
        "![](https://raw.githubusercontent.com/jmaronas/TGP.pytorch/master/images/2D_GP.gif)\n",
        "\n",
        "**Задание 1.4 (0.5 балла)**. Выведите аналитическую формулу для подсчета EI в случае $p(y|x) = \\mathcal{N}\\big(y\\big|\\mu(x), \\sigma^2(x)\\big)$ (подсказка: вам может пригодится значение функции распределения нормальной с.в.).\n",
        "\n",
        "$$\n",
        "\\text{EI}_{y^*}(x) = \\int \\max(0, y - y^*) p(y|x) dy = \\dots\n",
        "$$\n",
        "\n",
        "####Expected improvement\n",
        "taken from here http://krasserm.github.io/2018/03/21/bayesian-optimization/\n",
        "\n",
        "Expected improvement is defined as\n",
        "$$\n",
        "\\mathrm{EI}(\\mathbf{x})=\\mathbb{E} \\max \\left(f(\\mathbf{x})-f\\left(\\mathbf{x}^{+}\\right), 0\\right)\n",
        "$$\n",
        "\n",
        "where $f\\left(\\mathbf{x}^{+}\\right)$is the value of the best sample so far and $\\mathbf{x}^{+}$is the location of that sample i.e. $\\mathbf{x}^{+}=\\operatorname{argmax}_{\\mathbf{x}_i \\in \\mathbf{x}_{1: t}} f\\left(\\mathbf{x}_i\\right)$. The expected improvement can be evaluated analytically under the GP mode[[3]:\n",
        "\n",
        "$$\n",
        "\\mathrm{EI}(\\mathbf{x})= \\begin{cases}\\left(\\mu(\\mathbf{x})-f\\left(\\mathbf{x}^{+}\\right)-\\xi\\right) \\Phi(Z)+\\sigma(\\mathbf{x}) \\phi(Z) & \\text { if } \\sigma(\\mathbf{x})>0 \\\\ 0 & \\text { if } \\sigma(\\mathbf{x})=0\\end{cases}\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "$$\n",
        "Z= \\begin{cases}\\frac{\\mu(\\mathbf{x})-f\\left(\\mathbf{x}^{+}\\right)-\\xi}{\\sigma(\\mathbf{x})} & \\text { if } \\sigma(\\mathbf{x})>0 \\\\ 0 & \\text { if } \\sigma(\\mathbf{x})=0\\end{cases}\n",
        "$$\n",
        "\n",
        "where $\\mu(\\mathbf{x})$ and $\\sigma(\\mathbf{x})$ are the mean and the standard deviation of the GP posterior predictive at $\\mathbf{x}$, respectively. $\\Phi$ and $\\phi$ are the CDF and PDF of the standard normal distribution, respectively. The first summation term in Equation (2) is the exploitation term and second summation term is the exploration term.\n",
        "\n",
        "\n",
        "\n",
        "Теперь разберемся, как адаптировать ГП под наши нужды. Предлагается следующий план действий:\n",
        "\n",
        "1. Пускай на очередной итерации алгоритма $j$ у нас есть выборка $\\{(x_i, y_i)\\}_{i=1}^{j-1}$, где $x_i$ &mdash; значение набора гиперпараметров, а $y_i$ &mdash; соответствующее ему значение метрики, посчитанное по кросс-валидации.\n",
        "\n",
        "\n",
        "2. Если размер выборки меньше значения `self.num_dry_runs`, то возвращаем случайное значение гиперпараметров вместо запуска алгоритма. Таким образом, первые `self.num_dry_runs` итераций поиска подчиняются случайной стратегии, чтобы \"набрать статистику\" для работы алгоритма.\n",
        "\n",
        "\n",
        "3. ГП работает только с непрерывными величинами, поэтому давайте переведем значения гиперпараметров в диапазон $[0, 1]$ (тут-то нам и понадобится функция `scale`) и получим отнормированные гиперпараметры $x_i \\to \\tilde{x}_i$. Как вы догадываетесь, такой трюк сработает только с численными гиперпараметрами (как с непрерывными, так и с дискретными). Что делать с категориальными гиперпараметрами, обсудим позже.\n",
        "\n",
        "\n",
        "4. Далее обучаем ГП на выборку $\\{(\\tilde{x}_i, y_i)\\}_{i=1}^{j-1}$ (в качестве ковариационной функции возьмите сумму константного, белого и RBF ядер).\n",
        "\n",
        "\n",
        "5. Семплируем кандидатов в новые значения гиперпараметров $x^{\\text{new}}_1, ..., x^{\\text{new}}_N$ и преобразуем их функцией `scale`. Для каждого набора предсказываем параметры распределения $\\mu(\\tilde{x}), \\sigma^2(\\tilde{x})$, затем вычисляем $\\text{EI}_{y^*}(\\tilde{x})$ по формуле, посчитанной вами выше, и выбираем набор гиперпараметров $\\tilde{x}^\\text{new}_{*}$ с наибольшим значением EI.\n",
        "\n",
        "\n",
        "6. Выбираем исходный набор гиперпараметров $x^\\text{new}_{*}$, соответствующий $\\tilde{x}^\\text{new}_{*}$. Вуаля! Мы получили новый набор численных гиперпараметров, на котором будем валидировать модель.\n",
        "\n",
        "\n",
        "Для категориальных гиперпараметров попробуем провернуть что-нибудь похожее. Пусть у нас есть выборка $\\{(f_i, y_i)\\}_{i=1}^{j-1}$, где $f$ &mdash; интересующий нас категориальный гиперпараметр, $f_i \\in \\{1, \\dots, C\\}$ &mdash; конечное множество категорий. Зафиксируем $c \\in \\{1, \\dots, C\\}$ и рассмотрим $p(y|с) = \\mathcal{N}\\big(y\\big|\\mu(с), \\sigma^2(с)\\big)$. Определим параметры распределений следующим образом (как среднее и сглаженную дисперсию по категории):\n",
        "\n",
        "$$\n",
        "\\mu(c) = \\begin{cases}\n",
        "    \\cfrac{\\sum_i [f_i = c] \\cdot y_i}{\\sum_i [f_i = c]},& \\sum_i [f_i = c] > 0 \\\\\n",
        "    y^*,& \\sum_i [f_i = c] = 0\n",
        "\\end{cases}\n",
        "\\quad\\quad\\quad\n",
        "\\sigma^2(c) = \\frac{1 + \\sum_i [f_i = c] (y_i - \\mu(c))^2}{1 + \\sum_i [f_i = c]}\n",
        "$$\n",
        "\n",
        "В итоге, как и в случае с численными гиперпараметрами, мы находим категорию с лучшей EI. Впрочем, обычно такие гиперпараметры имеют не очень много возможных значений (скажем, не больше 10 категорий, а в реальности скорее 2-3: например, критерий при построении дерева), поэтому мы можем себе позволить **перебрать все значения** категориального признака **вместо семплирования** (что и требуется от вас в реализации). Обратите внимание, что категориальные гиперпараметры нужно обрабатывать отдельно (то есть они не имеют ничего общего с ГП, который мы обучаем по численным гиперпараметрам). Конечно, у такого подхода есть значительный минус: категории рассматриваются независимо друг от друга и от численных гиперпараметров, но уж лучше так, чем никак.\n",
        "\n",
        "**Задание 1.5 (1 балл)**. Реализуйте недостающие методы в классе `GPOptimizer` в файле `optimizers.py`. Задачи в контесте: [раз](https://contest.yandex.ru/contest/37803/problems/С/), [два](https://contest.yandex.ru/contest/37803/problems/D/)\n",
        "\n",
        "### Tree-structured Parzen estimator (TPE)\n",
        "\n",
        "Рассмотрим иной подход к приближению распределения $p(y|x)$. Он основан на использовании формулы Байеса:\n",
        "\n",
        "$$\n",
        "p(y|x) = \\frac{p(x|y)p(y)}{p(x)}\n",
        "$$\n",
        "\n",
        "Эта формула позволяет нам моделировать распределение $p(x|y)$ вместо $p(y|x)$. Обозначим за $y^*$ $\\gamma$-квантиль распределения $p(y)$, то есть $p(y < y^*)=\\gamma$ (в отличие от ГП, где $y^*$ выступает как максимум распределения). Идея TPE заключается в следующем выражении для плотности $p(x|y)$:\n",
        "\n",
        "$$\n",
        "p(x|y) = \\begin{cases}\n",
        "    g(x),& y \\ge y* \\\\\n",
        "    l(x),& y < y^*,\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "где $l(x)$ &mdash; это аппроксимация распределения $x$ при значениях целевой метрики меньше порогового $y^*$, а $g(x)$ &mdash; наоборот, выше порогового. Оказывается, что такой способ задать распределение позволяет нам очень просто находить максимум EI:\n",
        "\n",
        "**Задание 1.6 (0.5 балла)**. Докажите, что точка максимума EI совпадает с точкой максимума $\\cfrac{g(x)}{l(x)}$.\n",
        "\n",
        "$$\n",
        "\\text{EI}_{y^*}(x) = \\int \\max(0, y - y^*) p(y|x) dy = \\dots\n",
        "$$\n",
        "\n",
        "Таким образом, мы можем разделить все опробованные наборы гиперпараметров на две группы по значению целевой метрики, на каждой из них обучить свою оценку плотности ($g(x)$ или $l(x)$) и выбрать в качестве кандидата тот набор гиперпараметров, который имеет набольшее отношение плотностей. Такая процедура будет гарантировать нам максимизацию EI. В качестве алгоритма для приближения плотности мы будем пользоваться методом Парзеновского окна (он же Kernel Density Estimation, KDE), что и объясняет название оптимизатора (кстати, именно TPE находится под капотом у `optuna`). Как вы догадываетесь, KDE тоже реализован в [`sklearn.neighbors.KernelDensity`](https://www.youtube.com/watch?v=dQw4w9WgXcQ). И снова, такой подход позволяет обрабатывать только численные гиперпараметры. Получаем следующий алгоритм:\n",
        "\n",
        "1. Пускай на очередной итерации алгоритма $j$ у нас есть выборка $\\{(x_i, y_i)\\}_{i=1}^{j-1}$, где $x_i$ &mdash; значение набора гиперпараметров, а $y_i$ &mdash; соответствующее ему значение метрики, посчитанное по кросс-валидации.\n",
        "\n",
        "\n",
        "2. Если размер выборки меньше значения `self.num_dry_runs`, то возвращаем случайное значение гиперпараметров вместо запуска алгоритма.\n",
        "\n",
        "\n",
        "3. Переводим значения гиперпараметров в диапазон $[0, 1]$ и получаем отнормированные гиперпараметры $x_i \\to \\tilde{x}_i$.\n",
        "\n",
        "\n",
        "4. Считаем $\\gamma$-квантиль выборки $y_1, \\dots, y_{j-1}$ и делим значения гиперпараметров $\\tilde{x}_1, \\dots, \\tilde{x}_{j-1}$ на две группы (воспользуйтесь `np.quantile`).\n",
        "\n",
        "\n",
        "5. На каждой группе обучаем KDE, чтобы получить оценки $g(\\tilde{x})$ и $l(\\tilde{x})$ (обратите внимание, что алгоритм возвращает логарифм оценки плотности). Используйте гауссовское ядро, в качестве параметра `bandwidth` возьмите медианное расстояние до 1-го ближайшего соседа в полной выборке. Остальные параметры оставьте по умолчанию.\n",
        "\n",
        "\n",
        "6. Семплируем кандидатов в новые значения гиперпараметров $x^{\\text{new}}_1, ..., x^{\\text{new}}_N$ и преобразуем их функцией `scale`. Определяем точку:\n",
        "\n",
        "$$\n",
        "\\tilde{x}^\\text{new}_{*} = \\arg\\max_{i} \\bigg\\{\\frac{g(\\tilde{x}^{\\text{new}}_i)}{l(\\tilde{x}^{\\text{new}}_i)}\\bigg\\}\n",
        "$$\n",
        "\n",
        "\n",
        "7. Выбираем исходный набор гиперпараметров $x^\\text{new}_{*}$, соответствующий $\\tilde{x}^\\text{new}_{*}$.\n",
        "\n",
        "\n",
        "Для категориальных гиперпараметров $f_i \\in \\{1, \\dots, C\\}$ нам тоже нужно определить $g(x)$ и $l(x)$. Определим вероятность категории $с \\in \\{1, \\dots, C\\}$ пропорциональной следующей величине:\n",
        "\n",
        "$$\n",
        "p(c) \\propto N p_c + \\sum_i [f_i = c],\n",
        "$$\n",
        "\n",
        "где $N$ &mdash; число наборов гиперпараметров в группе (то есть это количество будет различным для $g(c)$ и $l(c)$), а $p_c$ &mdash; априорная вероятность категории (в нашем случае категории априорно равновероятны, $p_c = 1\\,/\\,C$). Сама вероятность $p(c)$ получается нормировкой по всем категориям гиперпараметра. И снова, мы будем **перебирать все значения** категориального признака **вместо семплирования**. Как и в случае ГП, категориальные гиперпараметры будут учитываться независимо от численных и друг от друга (тут даже можно выписать факторизацию распределения в виде $g(x) = g_{\\text{num}}(x_\\text{num}) \\prod_{\\text{cat}} g_{\\text{cat}}(x_\\text{cat})$, аналогично для $l(x)$, пусть эти формулы и не используются явно).\n",
        "\n",
        "Выглядит итерация метода примерно так:\n",
        "\n",
        "![](https://camo.githubusercontent.com/d14da729457267a66ebc9942b1ce57372adad287b74a1af5e0793f283c9bf1aa/687474703a2f2f6e657570792e636f6d2f5f696d616765732f7470652d73616d706c65642d63616e646964617465732e706e67)\n",
        "\n",
        "**Задание 1.7 (1 балл)**. Реализуйте недостающие методы в классе `TPEOptimizer` в файле `optimizers.py`. Задачи в контесте: [раз](https://contest.yandex.ru/contest/37803/problems/E/), [два](https://contest.yandex.ru/contest/37803/problems/F/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "generous-latex",
      "metadata": {
        "id": "generous-latex"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "noted-cooking",
      "metadata": {
        "id": "noted-cooking"
      },
      "outputs": [],
      "source": [
        "import distributions as D\n",
        "import optimizers as O"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-expense",
      "metadata": {
        "id": "acquired-expense"
      },
      "source": [
        "## 2. Эксперименты (5 баллов)\n",
        "\n",
        "**Задание 2.1 (1 балл)**. Сгенерируйте случайную выборку наборов гиперпараметров и выборку значений метрик. Замерьте время работы метода `select_params` для `GPOptimizer` и `TPEOptimizer`. Постройте график зависимости времени работы от размера выборки, сделайте выводы. Какую алгоритмическую сложность имеют алгоритмы?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "competent-hungary",
      "metadata": {
        "id": "competent-hungary"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "medium-encoding",
      "metadata": {
        "id": "medium-encoding"
      },
      "source": [
        "Дальнейшие эксперименты будет проводить на [наборе данных](https://www.kaggle.com/datasets/piyushagni5/white-wine-quality) о качестве белого вина.\n",
        "\n",
        "**Задание 2.2 (2 балла)**. Будем тестировать оптимизаторы на (барабанная дробь...) бустингах. Выберите библиотеку градиентного бустинга, которая приходится вам по душе и задайте распределения на гиперпараметры. Среди ваших гиперпараметров обязательно должны быть число деревьев, глубина дерева и learning rate, также добавьте еще 4-5 гиперпараметров по вашему желанию (среди них должен быть хотя бы один категориальный). Подумайте, какие распределения лучше всего подходят для каждого гиперпараметра.\n",
        "\n",
        "Как и всегда, разделите выборку на обучение и тест, предсказывать будем рейтинг вина (колонка `quality`). Хоть рейтинги и можно упорядочить, давайте решим задачу многоклассовой классификации на этих данных. В качестве метрики качества возьмем log loss. Мы будем сравнивать три стратегии для поиска, реализованные вами и [`OptunaSearchCV`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.OptunaSearchCV.html#optuna.integration.OptunaSearchCV) из библиотеки `optuna`, который имеет такой же интерфейс. Давайте ограничим наш бюджет поиска 40 итерациями. Обучите каждый из этих четырех методов по нескольку раз, чтобы посмотреть на дисперсию метрики (как минимум 3 раза, а в идеале раз 5, если позволяет время)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "national-richardson",
      "metadata": {
        "id": "national-richardson"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "desperate-float",
      "metadata": {
        "id": "desperate-float"
      },
      "source": [
        "Теперь попробуем визуализировать, что у нас получилось. Сделайте 4 сабплота, по одному на каждую стратегию поиска. На каждом графике изобразите лучшее найденное значение метрики, усредненное по запускам алгоритма, против номера итерации. Также нарисуйте область ± одного стандартного отклонения лучшего значения метрики. Кроме того, на том же графике сделайте scatter-plot **(номер итерации, значение метрики)** для этого запуска (именно для текущего набора гиперпараметра с итерации, а не лучшее, как для прошлого графика). Можете рисовать scatter-plot для всех повторных запусков сразу.\n",
        "\n",
        "Прокомментируйте наблюдаемое. Какой(-ие) алгоритм(-ы) показали себя лучше всего? Какой(-ие) можно назвать более стабильным(-и)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "racial-ghana",
      "metadata": {
        "id": "racial-ghana"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-notion",
      "metadata": {
        "id": "pending-notion"
      },
      "source": [
        "**Задание 2.3 (1 балл).** Теперь посмотрим на распределение $p(y|x)$, которое получилось у `GPOptimizer`. Рассмотрим плоскость значений гиперпараметров числа деревьев и learning rate. Настройте ГП на выборку истории значений этих двух гиперпараметров одного из `GPOptimizer`, обученных вами выше. Ядро возьмите такое же, какое использовалось при поиске. Визуализируйте среднее, которое предсказывает ГП на плоскости (вам поможет `plt.imshow` или `plt.scatter`). Также добавьте на рисунок точки из истории поиска. Не забудьте про colorbar'ы и правильные подписи отметок на осях. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "greek-exclusion",
      "metadata": {
        "id": "greek-exclusion"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ambient-parade",
      "metadata": {
        "id": "ambient-parade"
      },
      "source": [
        "**Задание 2.4 (0.5 балла)**. Аналогичным образом визуализируйте значения $\\log g(x)$ и $\\log l(x)$ на той же плоскости для `TPEOptimizer`. Параметр `bandwidth` оценивайте так же, как и в алгоритме поиска. Не забудьте добавить на рисунок точки из истории поиска (каждую из двух групп поместите на свой график). Что можно сказать о получившихся распределениях?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "crucial-ownership",
      "metadata": {
        "id": "crucial-ownership"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-observation",
      "metadata": {
        "id": "final-observation"
      },
      "source": [
        "**Задание 2.5 (0.5 балла)**. И на последок визуализируем, как изменялись распределения для категориального гиперпараметра у разных стратегий поиска. В этом пункте вам предлагается построить три рисунка:\n",
        "\n",
        "1. Ддя `GPOptimizer`: постройте графики $\\mu(c) \\pm \\sigma(c)$ для каждой категории $c$ против номера итерации (все на одном рисунке).\n",
        "\n",
        "\n",
        "2. Для `TPEOptimizer`: постройте area plot для значений $g(c)$ против номера итерации.\n",
        "\n",
        "\n",
        "3. Аналогично пункту 2 для значений $l(c)$.\n",
        "\n",
        "Прокомментируйте то, что получилось."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "molecular-documentation",
      "metadata": {
        "id": "molecular-documentation"
      },
      "outputs": [],
      "source": [
        "# Your code here (⊃｡•́‿•̀｡)⊃"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}